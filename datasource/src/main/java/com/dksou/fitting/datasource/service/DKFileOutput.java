/**
 * Autogenerated by Thrift Compiler (0.11.0)
 *
 * DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING
 *  @generated
 */
package com.dksou.fitting.datasource.service;

@SuppressWarnings({"cast", "rawtypes", "serial", "unchecked", "unused"})
@javax.annotation.Generated(value = "Autogenerated by Thrift Compiler (0.11.0)", date = "2019-06-21")
public class DKFileOutput {

  public interface Iface {

    /**
     * @param exportDir  hdfs下载的文件名（路径+文件名全称）
     * @param dkFileConf dkFile服务的配置项：参考说明文档
     * @return
     * @throws TException
     * 
     * @param exportDir
     * @param dkFileConf
     */
    public FileData hdfsToFileByBinary(java.lang.String exportDir, DKFILEConf dkFileConf) throws org.apache.thrift.TException;

    /**
     * @param filePath   为本地文件目录名
     * @param exportDir  要从hdfs导出的目录
     * @param dkFileConf dkFile服务的配置项：参考说明文档
     * @return
     * @throws TException
     * 
     * @param filePath
     * @param exportDir
     * @param dkFileConf
     */
    public ResultEntity hdfsToFiles(java.lang.String filePath, java.lang.String exportDir, DKFILEConf dkFileConf) throws org.apache.thrift.TException;

  }

  public interface AsyncIface {

    public void hdfsToFileByBinary(java.lang.String exportDir, DKFILEConf dkFileConf, org.apache.thrift.async.AsyncMethodCallback<FileData> resultHandler) throws org.apache.thrift.TException;

    public void hdfsToFiles(java.lang.String filePath, java.lang.String exportDir, DKFILEConf dkFileConf, org.apache.thrift.async.AsyncMethodCallback<ResultEntity> resultHandler) throws org.apache.thrift.TException;

  }

  public static class Client extends org.apache.thrift.TServiceClient implements Iface {
    public static class Factory implements org.apache.thrift.TServiceClientFactory<Client> {
      public Factory() {}
      public Client getClient(org.apache.thrift.protocol.TProtocol prot) {
        return new Client(prot);
      }
      public Client getClient(org.apache.thrift.protocol.TProtocol iprot, org.apache.thrift.protocol.TProtocol oprot) {
        return new Client(iprot, oprot);
      }
    }

    public Client(org.apache.thrift.protocol.TProtocol prot)
    {
      super(prot, prot);
    }

    public Client(org.apache.thrift.protocol.TProtocol iprot, org.apache.thrift.protocol.TProtocol oprot) {
      super(iprot, oprot);
    }

    public FileData hdfsToFileByBinary(java.lang.String exportDir, DKFILEConf dkFileConf) throws org.apache.thrift.TException
    {
      send_hdfsToFileByBinary(exportDir, dkFileConf);
      return recv_hdfsToFileByBinary();
    }

    public void send_hdfsToFileByBinary(java.lang.String exportDir, DKFILEConf dkFileConf) throws org.apache.thrift.TException
    {
      hdfsToFileByBinary_args args = new hdfsToFileByBinary_args();
      args.setExportDir(exportDir);
      args.setDkFileConf(dkFileConf);
      sendBase("hdfsToFileByBinary", args);
    }

    public FileData recv_hdfsToFileByBinary() throws org.apache.thrift.TException
    {
      hdfsToFileByBinary_result result = new hdfsToFileByBinary_result();
      receiveBase(result, "hdfsToFileByBinary");
      if (result.isSetSuccess()) {
        return result.success;
      }
      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, "hdfsToFileByBinary failed: unknown result");
    }

    public ResultEntity hdfsToFiles(java.lang.String filePath, java.lang.String exportDir, DKFILEConf dkFileConf) throws org.apache.thrift.TException
    {
      send_hdfsToFiles(filePath, exportDir, dkFileConf);
      return recv_hdfsToFiles();
    }

    public void send_hdfsToFiles(java.lang.String filePath, java.lang.String exportDir, DKFILEConf dkFileConf) throws org.apache.thrift.TException
    {
      hdfsToFiles_args args = new hdfsToFiles_args();
      args.setFilePath(filePath);
      args.setExportDir(exportDir);
      args.setDkFileConf(dkFileConf);
      sendBase("hdfsToFiles", args);
    }

    public ResultEntity recv_hdfsToFiles() throws org.apache.thrift.TException
    {
      hdfsToFiles_result result = new hdfsToFiles_result();
      receiveBase(result, "hdfsToFiles");
      if (result.isSetSuccess()) {
        return result.success;
      }
      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, "hdfsToFiles failed: unknown result");
    }

  }
  public static class AsyncClient extends org.apache.thrift.async.TAsyncClient implements AsyncIface {
    public static class Factory implements org.apache.thrift.async.TAsyncClientFactory<AsyncClient> {
      private org.apache.thrift.async.TAsyncClientManager clientManager;
      private org.apache.thrift.protocol.TProtocolFactory protocolFactory;
      public Factory(org.apache.thrift.async.TAsyncClientManager clientManager, org.apache.thrift.protocol.TProtocolFactory protocolFactory) {
        this.clientManager = clientManager;
        this.protocolFactory = protocolFactory;
      }
      public AsyncClient getAsyncClient(org.apache.thrift.transport.TNonblockingTransport transport) {
        return new AsyncClient(protocolFactory, clientManager, transport);
      }
    }

    public AsyncClient(org.apache.thrift.protocol.TProtocolFactory protocolFactory, org.apache.thrift.async.TAsyncClientManager clientManager, org.apache.thrift.transport.TNonblockingTransport transport) {
      super(protocolFactory, clientManager, transport);
    }

    public void hdfsToFileByBinary(java.lang.String exportDir, DKFILEConf dkFileConf, org.apache.thrift.async.AsyncMethodCallback<FileData> resultHandler) throws org.apache.thrift.TException {
      checkReady();
      hdfsToFileByBinary_call method_call = new hdfsToFileByBinary_call(exportDir, dkFileConf, resultHandler, this, ___protocolFactory, ___transport);
      this.___currentMethod = method_call;
      ___manager.call(method_call);
    }

    public static class hdfsToFileByBinary_call extends org.apache.thrift.async.TAsyncMethodCall<FileData> {
      private java.lang.String exportDir;
      private DKFILEConf dkFileConf;
      public hdfsToFileByBinary_call(java.lang.String exportDir, DKFILEConf dkFileConf, org.apache.thrift.async.AsyncMethodCallback<FileData> resultHandler, org.apache.thrift.async.TAsyncClient client, org.apache.thrift.protocol.TProtocolFactory protocolFactory, org.apache.thrift.transport.TNonblockingTransport transport) throws org.apache.thrift.TException {
        super(client, protocolFactory, transport, resultHandler, false);
        this.exportDir = exportDir;
        this.dkFileConf = dkFileConf;
      }

      public void write_args(org.apache.thrift.protocol.TProtocol prot) throws org.apache.thrift.TException {
        prot.writeMessageBegin(new org.apache.thrift.protocol.TMessage("hdfsToFileByBinary", org.apache.thrift.protocol.TMessageType.CALL, 0));
        hdfsToFileByBinary_args args = new hdfsToFileByBinary_args();
        args.setExportDir(exportDir);
        args.setDkFileConf(dkFileConf);
        args.write(prot);
        prot.writeMessageEnd();
      }

      public FileData getResult() throws org.apache.thrift.TException {
        if (getState() != org.apache.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {
          throw new java.lang.IllegalStateException("Method call not finished!");
        }
        org.apache.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());
        org.apache.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);
        return (new Client(prot)).recv_hdfsToFileByBinary();
      }
    }

    public void hdfsToFiles(java.lang.String filePath, java.lang.String exportDir, DKFILEConf dkFileConf, org.apache.thrift.async.AsyncMethodCallback<ResultEntity> resultHandler) throws org.apache.thrift.TException {
      checkReady();
      hdfsToFiles_call method_call = new hdfsToFiles_call(filePath, exportDir, dkFileConf, resultHandler, this, ___protocolFactory, ___transport);
      this.___currentMethod = method_call;
      ___manager.call(method_call);
    }

    public static class hdfsToFiles_call extends org.apache.thrift.async.TAsyncMethodCall<ResultEntity> {
      private java.lang.String filePath;
      private java.lang.String exportDir;
      private DKFILEConf dkFileConf;
      public hdfsToFiles_call(java.lang.String filePath, java.lang.String exportDir, DKFILEConf dkFileConf, org.apache.thrift.async.AsyncMethodCallback<ResultEntity> resultHandler, org.apache.thrift.async.TAsyncClient client, org.apache.thrift.protocol.TProtocolFactory protocolFactory, org.apache.thrift.transport.TNonblockingTransport transport) throws org.apache.thrift.TException {
        super(client, protocolFactory, transport, resultHandler, false);
        this.filePath = filePath;
        this.exportDir = exportDir;
        this.dkFileConf = dkFileConf;
      }

      public void write_args(org.apache.thrift.protocol.TProtocol prot) throws org.apache.thrift.TException {
        prot.writeMessageBegin(new org.apache.thrift.protocol.TMessage("hdfsToFiles", org.apache.thrift.protocol.TMessageType.CALL, 0));
        hdfsToFiles_args args = new hdfsToFiles_args();
        args.setFilePath(filePath);
        args.setExportDir(exportDir);
        args.setDkFileConf(dkFileConf);
        args.write(prot);
        prot.writeMessageEnd();
      }

      public ResultEntity getResult() throws org.apache.thrift.TException {
        if (getState() != org.apache.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {
          throw new java.lang.IllegalStateException("Method call not finished!");
        }
        org.apache.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());
        org.apache.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);
        return (new Client(prot)).recv_hdfsToFiles();
      }
    }

  }

  public static class Processor<I extends Iface> extends org.apache.thrift.TBaseProcessor<I> implements org.apache.thrift.TProcessor {
    private static final org.slf4j.Logger _LOGGER = org.slf4j.LoggerFactory.getLogger(Processor.class.getName());
    public Processor(I iface) {
      super(iface, getProcessMap(new java.util.HashMap<java.lang.String, org.apache.thrift.ProcessFunction<I, ? extends org.apache.thrift.TBase>>()));
    }

    protected Processor(I iface, java.util.Map<java.lang.String, org.apache.thrift.ProcessFunction<I, ? extends org.apache.thrift.TBase>> processMap) {
      super(iface, getProcessMap(processMap));
    }

    private static <I extends Iface> java.util.Map<java.lang.String,  org.apache.thrift.ProcessFunction<I, ? extends org.apache.thrift.TBase>> getProcessMap(java.util.Map<java.lang.String, org.apache.thrift.ProcessFunction<I, ? extends  org.apache.thrift.TBase>> processMap) {
      processMap.put("hdfsToFileByBinary", new hdfsToFileByBinary());
      processMap.put("hdfsToFiles", new hdfsToFiles());
      return processMap;
    }

    public static class hdfsToFileByBinary<I extends Iface> extends org.apache.thrift.ProcessFunction<I, hdfsToFileByBinary_args> {
      public hdfsToFileByBinary() {
        super("hdfsToFileByBinary");
      }

      public hdfsToFileByBinary_args getEmptyArgsInstance() {
        return new hdfsToFileByBinary_args();
      }

      protected boolean isOneway() {
        return false;
      }

      @Override
      protected boolean handleRuntimeExceptions() {
        return false;
      }

      public hdfsToFileByBinary_result getResult(I iface, hdfsToFileByBinary_args args) throws org.apache.thrift.TException {
        hdfsToFileByBinary_result result = new hdfsToFileByBinary_result();
        result.success = iface.hdfsToFileByBinary(args.exportDir, args.dkFileConf);
        return result;
      }
    }

    public static class hdfsToFiles<I extends Iface> extends org.apache.thrift.ProcessFunction<I, hdfsToFiles_args> {
      public hdfsToFiles() {
        super("hdfsToFiles");
      }

      public hdfsToFiles_args getEmptyArgsInstance() {
        return new hdfsToFiles_args();
      }

      protected boolean isOneway() {
        return false;
      }

      @Override
      protected boolean handleRuntimeExceptions() {
        return false;
      }

      public hdfsToFiles_result getResult(I iface, hdfsToFiles_args args) throws org.apache.thrift.TException {
        hdfsToFiles_result result = new hdfsToFiles_result();
        result.success = iface.hdfsToFiles(args.filePath, args.exportDir, args.dkFileConf);
        return result;
      }
    }

  }

  public static class AsyncProcessor<I extends AsyncIface> extends org.apache.thrift.TBaseAsyncProcessor<I> {
    private static final org.slf4j.Logger _LOGGER = org.slf4j.LoggerFactory.getLogger(AsyncProcessor.class.getName());
    public AsyncProcessor(I iface) {
      super(iface, getProcessMap(new java.util.HashMap<java.lang.String, org.apache.thrift.AsyncProcessFunction<I, ? extends org.apache.thrift.TBase, ?>>()));
    }

    protected AsyncProcessor(I iface, java.util.Map<java.lang.String,  org.apache.thrift.AsyncProcessFunction<I, ? extends  org.apache.thrift.TBase, ?>> processMap) {
      super(iface, getProcessMap(processMap));
    }

    private static <I extends AsyncIface> java.util.Map<java.lang.String,  org.apache.thrift.AsyncProcessFunction<I, ? extends  org.apache.thrift.TBase,?>> getProcessMap(java.util.Map<java.lang.String,  org.apache.thrift.AsyncProcessFunction<I, ? extends  org.apache.thrift.TBase, ?>> processMap) {
      processMap.put("hdfsToFileByBinary", new hdfsToFileByBinary());
      processMap.put("hdfsToFiles", new hdfsToFiles());
      return processMap;
    }

    public static class hdfsToFileByBinary<I extends AsyncIface> extends org.apache.thrift.AsyncProcessFunction<I, hdfsToFileByBinary_args, FileData> {
      public hdfsToFileByBinary() {
        super("hdfsToFileByBinary");
      }

      public hdfsToFileByBinary_args getEmptyArgsInstance() {
        return new hdfsToFileByBinary_args();
      }

      public org.apache.thrift.async.AsyncMethodCallback<FileData> getResultHandler(final org.apache.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {
        final org.apache.thrift.AsyncProcessFunction fcall = this;
        return new org.apache.thrift.async.AsyncMethodCallback<FileData>() { 
          public void onComplete(FileData o) {
            hdfsToFileByBinary_result result = new hdfsToFileByBinary_result();
            result.success = o;
            try {
              fcall.sendResponse(fb, result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);
            } catch (org.apache.thrift.transport.TTransportException e) {
              _LOGGER.error("TTransportException writing to internal frame buffer", e);
              fb.close();
            } catch (java.lang.Exception e) {
              _LOGGER.error("Exception writing to internal frame buffer", e);
              onError(e);
            }
          }
          public void onError(java.lang.Exception e) {
            byte msgType = org.apache.thrift.protocol.TMessageType.REPLY;
            org.apache.thrift.TSerializable msg;
            hdfsToFileByBinary_result result = new hdfsToFileByBinary_result();
            if (e instanceof org.apache.thrift.transport.TTransportException) {
              _LOGGER.error("TTransportException inside handler", e);
              fb.close();
              return;
            } else if (e instanceof org.apache.thrift.TApplicationException) {
              _LOGGER.error("TApplicationException inside handler", e);
              msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;
              msg = (org.apache.thrift.TApplicationException)e;
            } else {
              _LOGGER.error("Exception inside handler", e);
              msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;
              msg = new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());
            }
            try {
              fcall.sendResponse(fb,msg,msgType,seqid);
            } catch (java.lang.Exception ex) {
              _LOGGER.error("Exception writing to internal frame buffer", ex);
              fb.close();
            }
          }
        };
      }

      protected boolean isOneway() {
        return false;
      }

      public void start(I iface, hdfsToFileByBinary_args args, org.apache.thrift.async.AsyncMethodCallback<FileData> resultHandler) throws org.apache.thrift.TException {
        iface.hdfsToFileByBinary(args.exportDir, args.dkFileConf,resultHandler);
      }
    }

    public static class hdfsToFiles<I extends AsyncIface> extends org.apache.thrift.AsyncProcessFunction<I, hdfsToFiles_args, ResultEntity> {
      public hdfsToFiles() {
        super("hdfsToFiles");
      }

      public hdfsToFiles_args getEmptyArgsInstance() {
        return new hdfsToFiles_args();
      }

      public org.apache.thrift.async.AsyncMethodCallback<ResultEntity> getResultHandler(final org.apache.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {
        final org.apache.thrift.AsyncProcessFunction fcall = this;
        return new org.apache.thrift.async.AsyncMethodCallback<ResultEntity>() { 
          public void onComplete(ResultEntity o) {
            hdfsToFiles_result result = new hdfsToFiles_result();
            result.success = o;
            try {
              fcall.sendResponse(fb, result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);
            } catch (org.apache.thrift.transport.TTransportException e) {
              _LOGGER.error("TTransportException writing to internal frame buffer", e);
              fb.close();
            } catch (java.lang.Exception e) {
              _LOGGER.error("Exception writing to internal frame buffer", e);
              onError(e);
            }
          }
          public void onError(java.lang.Exception e) {
            byte msgType = org.apache.thrift.protocol.TMessageType.REPLY;
            org.apache.thrift.TSerializable msg;
            hdfsToFiles_result result = new hdfsToFiles_result();
            if (e instanceof org.apache.thrift.transport.TTransportException) {
              _LOGGER.error("TTransportException inside handler", e);
              fb.close();
              return;
            } else if (e instanceof org.apache.thrift.TApplicationException) {
              _LOGGER.error("TApplicationException inside handler", e);
              msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;
              msg = (org.apache.thrift.TApplicationException)e;
            } else {
              _LOGGER.error("Exception inside handler", e);
              msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;
              msg = new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());
            }
            try {
              fcall.sendResponse(fb,msg,msgType,seqid);
            } catch (java.lang.Exception ex) {
              _LOGGER.error("Exception writing to internal frame buffer", ex);
              fb.close();
            }
          }
        };
      }

      protected boolean isOneway() {
        return false;
      }

      public void start(I iface, hdfsToFiles_args args, org.apache.thrift.async.AsyncMethodCallback<ResultEntity> resultHandler) throws org.apache.thrift.TException {
        iface.hdfsToFiles(args.filePath, args.exportDir, args.dkFileConf,resultHandler);
      }
    }

  }

  public static class hdfsToFileByBinary_args implements org.apache.thrift.TBase<hdfsToFileByBinary_args, hdfsToFileByBinary_args._Fields>, java.io.Serializable, Cloneable, Comparable<hdfsToFileByBinary_args>   {
    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("hdfsToFileByBinary_args");

    private static final org.apache.thrift.protocol.TField EXPORT_DIR_FIELD_DESC = new org.apache.thrift.protocol.TField("exportDir", org.apache.thrift.protocol.TType.STRING, (short)1);
    private static final org.apache.thrift.protocol.TField DK_FILE_CONF_FIELD_DESC = new org.apache.thrift.protocol.TField("dkFileConf", org.apache.thrift.protocol.TType.STRUCT, (short)2);

    private static final org.apache.thrift.scheme.SchemeFactory STANDARD_SCHEME_FACTORY = new hdfsToFileByBinary_argsStandardSchemeFactory();
    private static final org.apache.thrift.scheme.SchemeFactory TUPLE_SCHEME_FACTORY = new hdfsToFileByBinary_argsTupleSchemeFactory();

    public java.lang.String exportDir; // required
    public DKFILEConf dkFileConf; // required

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements org.apache.thrift.TFieldIdEnum {
      EXPORT_DIR((short)1, "exportDir"),
      DK_FILE_CONF((short)2, "dkFileConf");

      private static final java.util.Map<java.lang.String, _Fields> byName = new java.util.HashMap<java.lang.String, _Fields>();

      static {
        for (_Fields field : java.util.EnumSet.allOf(_Fields.class)) {
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        switch(fieldId) {
          case 1: // EXPORT_DIR
            return EXPORT_DIR;
          case 2: // DK_FILE_CONF
            return DK_FILE_CONF;
          default:
            return null;
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new java.lang.IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(java.lang.String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final java.lang.String _fieldName;

      _Fields(short thriftId, java.lang.String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public java.lang.String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments
    public static final java.util.Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
    static {
      java.util.Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new java.util.EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
      tmpMap.put(_Fields.EXPORT_DIR, new org.apache.thrift.meta_data.FieldMetaData("exportDir", org.apache.thrift.TFieldRequirementType.DEFAULT, 
          new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
      tmpMap.put(_Fields.DK_FILE_CONF, new org.apache.thrift.meta_data.FieldMetaData("dkFileConf", org.apache.thrift.TFieldRequirementType.DEFAULT, 
          new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, DKFILEConf.class)));
      metaDataMap = java.util.Collections.unmodifiableMap(tmpMap);
      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(hdfsToFileByBinary_args.class, metaDataMap);
    }

    public hdfsToFileByBinary_args() {
    }

    public hdfsToFileByBinary_args(
      java.lang.String exportDir,
      DKFILEConf dkFileConf)
    {
      this();
      this.exportDir = exportDir;
      this.dkFileConf = dkFileConf;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public hdfsToFileByBinary_args(hdfsToFileByBinary_args other) {
      if (other.isSetExportDir()) {
        this.exportDir = other.exportDir;
      }
      if (other.isSetDkFileConf()) {
        this.dkFileConf = new DKFILEConf(other.dkFileConf);
      }
    }

    public hdfsToFileByBinary_args deepCopy() {
      return new hdfsToFileByBinary_args(this);
    }

    @Override
    public void clear() {
      this.exportDir = null;
      this.dkFileConf = null;
    }

    public java.lang.String getExportDir() {
      return this.exportDir;
    }

    public hdfsToFileByBinary_args setExportDir(java.lang.String exportDir) {
      this.exportDir = exportDir;
      return this;
    }

    public void unsetExportDir() {
      this.exportDir = null;
    }

    /** Returns true if field exportDir is set (has been assigned a value) and false otherwise */
    public boolean isSetExportDir() {
      return this.exportDir != null;
    }

    public void setExportDirIsSet(boolean value) {
      if (!value) {
        this.exportDir = null;
      }
    }

    public DKFILEConf getDkFileConf() {
      return this.dkFileConf;
    }

    public hdfsToFileByBinary_args setDkFileConf(DKFILEConf dkFileConf) {
      this.dkFileConf = dkFileConf;
      return this;
    }

    public void unsetDkFileConf() {
      this.dkFileConf = null;
    }

    /** Returns true if field dkFileConf is set (has been assigned a value) and false otherwise */
    public boolean isSetDkFileConf() {
      return this.dkFileConf != null;
    }

    public void setDkFileConfIsSet(boolean value) {
      if (!value) {
        this.dkFileConf = null;
      }
    }

    public void setFieldValue(_Fields field, java.lang.Object value) {
      switch (field) {
      case EXPORT_DIR:
        if (value == null) {
          unsetExportDir();
        } else {
          setExportDir((java.lang.String)value);
        }
        break;

      case DK_FILE_CONF:
        if (value == null) {
          unsetDkFileConf();
        } else {
          setDkFileConf((DKFILEConf)value);
        }
        break;

      }
    }

    public java.lang.Object getFieldValue(_Fields field) {
      switch (field) {
      case EXPORT_DIR:
        return getExportDir();

      case DK_FILE_CONF:
        return getDkFileConf();

      }
      throw new java.lang.IllegalStateException();
    }

    /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      if (field == null) {
        throw new java.lang.IllegalArgumentException();
      }

      switch (field) {
      case EXPORT_DIR:
        return isSetExportDir();
      case DK_FILE_CONF:
        return isSetDkFileConf();
      }
      throw new java.lang.IllegalStateException();
    }

    @Override
    public boolean equals(java.lang.Object that) {
      if (that == null)
        return false;
      if (that instanceof hdfsToFileByBinary_args)
        return this.equals((hdfsToFileByBinary_args)that);
      return false;
    }

    public boolean equals(hdfsToFileByBinary_args that) {
      if (that == null)
        return false;
      if (this == that)
        return true;

      boolean this_present_exportDir = true && this.isSetExportDir();
      boolean that_present_exportDir = true && that.isSetExportDir();
      if (this_present_exportDir || that_present_exportDir) {
        if (!(this_present_exportDir && that_present_exportDir))
          return false;
        if (!this.exportDir.equals(that.exportDir))
          return false;
      }

      boolean this_present_dkFileConf = true && this.isSetDkFileConf();
      boolean that_present_dkFileConf = true && that.isSetDkFileConf();
      if (this_present_dkFileConf || that_present_dkFileConf) {
        if (!(this_present_dkFileConf && that_present_dkFileConf))
          return false;
        if (!this.dkFileConf.equals(that.dkFileConf))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      int hashCode = 1;

      hashCode = hashCode * 8191 + ((isSetExportDir()) ? 131071 : 524287);
      if (isSetExportDir())
        hashCode = hashCode * 8191 + exportDir.hashCode();

      hashCode = hashCode * 8191 + ((isSetDkFileConf()) ? 131071 : 524287);
      if (isSetDkFileConf())
        hashCode = hashCode * 8191 + dkFileConf.hashCode();

      return hashCode;
    }

    @Override
    public int compareTo(hdfsToFileByBinary_args other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;

      lastComparison = java.lang.Boolean.valueOf(isSetExportDir()).compareTo(other.isSetExportDir());
      if (lastComparison != 0) {
        return lastComparison;
      }
      if (isSetExportDir()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.exportDir, other.exportDir);
        if (lastComparison != 0) {
          return lastComparison;
        }
      }
      lastComparison = java.lang.Boolean.valueOf(isSetDkFileConf()).compareTo(other.isSetDkFileConf());
      if (lastComparison != 0) {
        return lastComparison;
      }
      if (isSetDkFileConf()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.dkFileConf, other.dkFileConf);
        if (lastComparison != 0) {
          return lastComparison;
        }
      }
      return 0;
    }

    public _Fields fieldForId(int fieldId) {
      return _Fields.findByThriftId(fieldId);
    }

    public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException {
      scheme(iprot).read(iprot, this);
    }

    public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException {
      scheme(oprot).write(oprot, this);
    }

    @Override
    public java.lang.String toString() {
      java.lang.StringBuilder sb = new java.lang.StringBuilder("hdfsToFileByBinary_args(");
      boolean first = true;

      sb.append("exportDir:");
      if (this.exportDir == null) {
        sb.append("null");
      } else {
        sb.append(this.exportDir);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("dkFileConf:");
      if (this.dkFileConf == null) {
        sb.append("null");
      } else {
        sb.append(this.dkFileConf);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws org.apache.thrift.TException {
      // check for required fields
      // check for sub-struct validity
      if (dkFileConf != null) {
        dkFileConf.validate();
      }
    }

    private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
      try {
        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));
      } catch (org.apache.thrift.TException te) {
        throw new java.io.IOException(te);
      }
    }

    private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, java.lang.ClassNotFoundException {
      try {
        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));
      } catch (org.apache.thrift.TException te) {
        throw new java.io.IOException(te);
      }
    }

    private static class hdfsToFileByBinary_argsStandardSchemeFactory implements org.apache.thrift.scheme.SchemeFactory {
      public hdfsToFileByBinary_argsStandardScheme getScheme() {
        return new hdfsToFileByBinary_argsStandardScheme();
      }
    }

    private static class hdfsToFileByBinary_argsStandardScheme extends org.apache.thrift.scheme.StandardScheme<hdfsToFileByBinary_args> {

      public void read(org.apache.thrift.protocol.TProtocol iprot, hdfsToFileByBinary_args struct) throws org.apache.thrift.TException {
        org.apache.thrift.protocol.TField schemeField;
        iprot.readStructBegin();
        while (true)
        {
          schemeField = iprot.readFieldBegin();
          if (schemeField.type == org.apache.thrift.protocol.TType.STOP) { 
            break;
          }
          switch (schemeField.id) {
            case 1: // EXPORT_DIR
              if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
                struct.exportDir = iprot.readString();
                struct.setExportDirIsSet(true);
              } else { 
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
              }
              break;
            case 2: // DK_FILE_CONF
              if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
                struct.dkFileConf = new DKFILEConf();
                struct.dkFileConf.read(iprot);
                struct.setDkFileConfIsSet(true);
              } else { 
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
              }
              break;
            default:
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
          }
          iprot.readFieldEnd();
        }
        iprot.readStructEnd();

        // check for required fields of primitive type, which can't be checked in the validate method
        struct.validate();
      }

      public void write(org.apache.thrift.protocol.TProtocol oprot, hdfsToFileByBinary_args struct) throws org.apache.thrift.TException {
        struct.validate();

        oprot.writeStructBegin(STRUCT_DESC);
        if (struct.exportDir != null) {
          oprot.writeFieldBegin(EXPORT_DIR_FIELD_DESC);
          oprot.writeString(struct.exportDir);
          oprot.writeFieldEnd();
        }
        if (struct.dkFileConf != null) {
          oprot.writeFieldBegin(DK_FILE_CONF_FIELD_DESC);
          struct.dkFileConf.write(oprot);
          oprot.writeFieldEnd();
        }
        oprot.writeFieldStop();
        oprot.writeStructEnd();
      }

    }

    private static class hdfsToFileByBinary_argsTupleSchemeFactory implements org.apache.thrift.scheme.SchemeFactory {
      public hdfsToFileByBinary_argsTupleScheme getScheme() {
        return new hdfsToFileByBinary_argsTupleScheme();
      }
    }

    private static class hdfsToFileByBinary_argsTupleScheme extends org.apache.thrift.scheme.TupleScheme<hdfsToFileByBinary_args> {

      @Override
      public void write(org.apache.thrift.protocol.TProtocol prot, hdfsToFileByBinary_args struct) throws org.apache.thrift.TException {
        org.apache.thrift.protocol.TTupleProtocol oprot = (org.apache.thrift.protocol.TTupleProtocol) prot;
        java.util.BitSet optionals = new java.util.BitSet();
        if (struct.isSetExportDir()) {
          optionals.set(0);
        }
        if (struct.isSetDkFileConf()) {
          optionals.set(1);
        }
        oprot.writeBitSet(optionals, 2);
        if (struct.isSetExportDir()) {
          oprot.writeString(struct.exportDir);
        }
        if (struct.isSetDkFileConf()) {
          struct.dkFileConf.write(oprot);
        }
      }

      @Override
      public void read(org.apache.thrift.protocol.TProtocol prot, hdfsToFileByBinary_args struct) throws org.apache.thrift.TException {
        org.apache.thrift.protocol.TTupleProtocol iprot = (org.apache.thrift.protocol.TTupleProtocol) prot;
        java.util.BitSet incoming = iprot.readBitSet(2);
        if (incoming.get(0)) {
          struct.exportDir = iprot.readString();
          struct.setExportDirIsSet(true);
        }
        if (incoming.get(1)) {
          struct.dkFileConf = new DKFILEConf();
          struct.dkFileConf.read(iprot);
          struct.setDkFileConfIsSet(true);
        }
      }
    }

    private static <S extends org.apache.thrift.scheme.IScheme> S scheme(org.apache.thrift.protocol.TProtocol proto) {
      return (org.apache.thrift.scheme.StandardScheme.class.equals(proto.getScheme()) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY).getScheme();
    }
  }

  public static class hdfsToFileByBinary_result implements org.apache.thrift.TBase<hdfsToFileByBinary_result, hdfsToFileByBinary_result._Fields>, java.io.Serializable, Cloneable, Comparable<hdfsToFileByBinary_result>   {
    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("hdfsToFileByBinary_result");

    private static final org.apache.thrift.protocol.TField SUCCESS_FIELD_DESC = new org.apache.thrift.protocol.TField("success", org.apache.thrift.protocol.TType.STRUCT, (short)0);

    private static final org.apache.thrift.scheme.SchemeFactory STANDARD_SCHEME_FACTORY = new hdfsToFileByBinary_resultStandardSchemeFactory();
    private static final org.apache.thrift.scheme.SchemeFactory TUPLE_SCHEME_FACTORY = new hdfsToFileByBinary_resultTupleSchemeFactory();

    public FileData success; // required

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements org.apache.thrift.TFieldIdEnum {
      SUCCESS((short)0, "success");

      private static final java.util.Map<java.lang.String, _Fields> byName = new java.util.HashMap<java.lang.String, _Fields>();

      static {
        for (_Fields field : java.util.EnumSet.allOf(_Fields.class)) {
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        switch(fieldId) {
          case 0: // SUCCESS
            return SUCCESS;
          default:
            return null;
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new java.lang.IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(java.lang.String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final java.lang.String _fieldName;

      _Fields(short thriftId, java.lang.String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public java.lang.String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments
    public static final java.util.Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
    static {
      java.util.Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new java.util.EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
      tmpMap.put(_Fields.SUCCESS, new org.apache.thrift.meta_data.FieldMetaData("success", org.apache.thrift.TFieldRequirementType.DEFAULT, 
          new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, FileData.class)));
      metaDataMap = java.util.Collections.unmodifiableMap(tmpMap);
      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(hdfsToFileByBinary_result.class, metaDataMap);
    }

    public hdfsToFileByBinary_result() {
    }

    public hdfsToFileByBinary_result(
      FileData success)
    {
      this();
      this.success = success;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public hdfsToFileByBinary_result(hdfsToFileByBinary_result other) {
      if (other.isSetSuccess()) {
        this.success = new FileData(other.success);
      }
    }

    public hdfsToFileByBinary_result deepCopy() {
      return new hdfsToFileByBinary_result(this);
    }

    @Override
    public void clear() {
      this.success = null;
    }

    public FileData getSuccess() {
      return this.success;
    }

    public hdfsToFileByBinary_result setSuccess(FileData success) {
      this.success = success;
      return this;
    }

    public void unsetSuccess() {
      this.success = null;
    }

    /** Returns true if field success is set (has been assigned a value) and false otherwise */
    public boolean isSetSuccess() {
      return this.success != null;
    }

    public void setSuccessIsSet(boolean value) {
      if (!value) {
        this.success = null;
      }
    }

    public void setFieldValue(_Fields field, java.lang.Object value) {
      switch (field) {
      case SUCCESS:
        if (value == null) {
          unsetSuccess();
        } else {
          setSuccess((FileData)value);
        }
        break;

      }
    }

    public java.lang.Object getFieldValue(_Fields field) {
      switch (field) {
      case SUCCESS:
        return getSuccess();

      }
      throw new java.lang.IllegalStateException();
    }

    /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      if (field == null) {
        throw new java.lang.IllegalArgumentException();
      }

      switch (field) {
      case SUCCESS:
        return isSetSuccess();
      }
      throw new java.lang.IllegalStateException();
    }

    @Override
    public boolean equals(java.lang.Object that) {
      if (that == null)
        return false;
      if (that instanceof hdfsToFileByBinary_result)
        return this.equals((hdfsToFileByBinary_result)that);
      return false;
    }

    public boolean equals(hdfsToFileByBinary_result that) {
      if (that == null)
        return false;
      if (this == that)
        return true;

      boolean this_present_success = true && this.isSetSuccess();
      boolean that_present_success = true && that.isSetSuccess();
      if (this_present_success || that_present_success) {
        if (!(this_present_success && that_present_success))
          return false;
        if (!this.success.equals(that.success))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      int hashCode = 1;

      hashCode = hashCode * 8191 + ((isSetSuccess()) ? 131071 : 524287);
      if (isSetSuccess())
        hashCode = hashCode * 8191 + success.hashCode();

      return hashCode;
    }

    @Override
    public int compareTo(hdfsToFileByBinary_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;

      lastComparison = java.lang.Boolean.valueOf(isSetSuccess()).compareTo(other.isSetSuccess());
      if (lastComparison != 0) {
        return lastComparison;
      }
      if (isSetSuccess()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.success, other.success);
        if (lastComparison != 0) {
          return lastComparison;
        }
      }
      return 0;
    }

    public _Fields fieldForId(int fieldId) {
      return _Fields.findByThriftId(fieldId);
    }

    public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException {
      scheme(iprot).read(iprot, this);
    }

    public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException {
      scheme(oprot).write(oprot, this);
      }

    @Override
    public java.lang.String toString() {
      java.lang.StringBuilder sb = new java.lang.StringBuilder("hdfsToFileByBinary_result(");
      boolean first = true;

      sb.append("success:");
      if (this.success == null) {
        sb.append("null");
      } else {
        sb.append(this.success);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws org.apache.thrift.TException {
      // check for required fields
      // check for sub-struct validity
      if (success != null) {
        success.validate();
      }
    }

    private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
      try {
        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));
      } catch (org.apache.thrift.TException te) {
        throw new java.io.IOException(te);
      }
    }

    private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, java.lang.ClassNotFoundException {
      try {
        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));
      } catch (org.apache.thrift.TException te) {
        throw new java.io.IOException(te);
      }
    }

    private static class hdfsToFileByBinary_resultStandardSchemeFactory implements org.apache.thrift.scheme.SchemeFactory {
      public hdfsToFileByBinary_resultStandardScheme getScheme() {
        return new hdfsToFileByBinary_resultStandardScheme();
      }
    }

    private static class hdfsToFileByBinary_resultStandardScheme extends org.apache.thrift.scheme.StandardScheme<hdfsToFileByBinary_result> {

      public void read(org.apache.thrift.protocol.TProtocol iprot, hdfsToFileByBinary_result struct) throws org.apache.thrift.TException {
        org.apache.thrift.protocol.TField schemeField;
        iprot.readStructBegin();
        while (true)
        {
          schemeField = iprot.readFieldBegin();
          if (schemeField.type == org.apache.thrift.protocol.TType.STOP) { 
            break;
          }
          switch (schemeField.id) {
            case 0: // SUCCESS
              if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
                struct.success = new FileData();
                struct.success.read(iprot);
                struct.setSuccessIsSet(true);
              } else { 
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
              }
              break;
            default:
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
          }
          iprot.readFieldEnd();
        }
        iprot.readStructEnd();

        // check for required fields of primitive type, which can't be checked in the validate method
        struct.validate();
      }

      public void write(org.apache.thrift.protocol.TProtocol oprot, hdfsToFileByBinary_result struct) throws org.apache.thrift.TException {
        struct.validate();

        oprot.writeStructBegin(STRUCT_DESC);
        if (struct.success != null) {
          oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
          struct.success.write(oprot);
          oprot.writeFieldEnd();
        }
        oprot.writeFieldStop();
        oprot.writeStructEnd();
      }

    }

    private static class hdfsToFileByBinary_resultTupleSchemeFactory implements org.apache.thrift.scheme.SchemeFactory {
      public hdfsToFileByBinary_resultTupleScheme getScheme() {
        return new hdfsToFileByBinary_resultTupleScheme();
      }
    }

    private static class hdfsToFileByBinary_resultTupleScheme extends org.apache.thrift.scheme.TupleScheme<hdfsToFileByBinary_result> {

      @Override
      public void write(org.apache.thrift.protocol.TProtocol prot, hdfsToFileByBinary_result struct) throws org.apache.thrift.TException {
        org.apache.thrift.protocol.TTupleProtocol oprot = (org.apache.thrift.protocol.TTupleProtocol) prot;
        java.util.BitSet optionals = new java.util.BitSet();
        if (struct.isSetSuccess()) {
          optionals.set(0);
        }
        oprot.writeBitSet(optionals, 1);
        if (struct.isSetSuccess()) {
          struct.success.write(oprot);
        }
      }

      @Override
      public void read(org.apache.thrift.protocol.TProtocol prot, hdfsToFileByBinary_result struct) throws org.apache.thrift.TException {
        org.apache.thrift.protocol.TTupleProtocol iprot = (org.apache.thrift.protocol.TTupleProtocol) prot;
        java.util.BitSet incoming = iprot.readBitSet(1);
        if (incoming.get(0)) {
          struct.success = new FileData();
          struct.success.read(iprot);
          struct.setSuccessIsSet(true);
        }
      }
    }

    private static <S extends org.apache.thrift.scheme.IScheme> S scheme(org.apache.thrift.protocol.TProtocol proto) {
      return (org.apache.thrift.scheme.StandardScheme.class.equals(proto.getScheme()) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY).getScheme();
    }
  }

  public static class hdfsToFiles_args implements org.apache.thrift.TBase<hdfsToFiles_args, hdfsToFiles_args._Fields>, java.io.Serializable, Cloneable, Comparable<hdfsToFiles_args>   {
    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("hdfsToFiles_args");

    private static final org.apache.thrift.protocol.TField FILE_PATH_FIELD_DESC = new org.apache.thrift.protocol.TField("filePath", org.apache.thrift.protocol.TType.STRING, (short)1);
    private static final org.apache.thrift.protocol.TField EXPORT_DIR_FIELD_DESC = new org.apache.thrift.protocol.TField("exportDir", org.apache.thrift.protocol.TType.STRING, (short)2);
    private static final org.apache.thrift.protocol.TField DK_FILE_CONF_FIELD_DESC = new org.apache.thrift.protocol.TField("dkFileConf", org.apache.thrift.protocol.TType.STRUCT, (short)3);

    private static final org.apache.thrift.scheme.SchemeFactory STANDARD_SCHEME_FACTORY = new hdfsToFiles_argsStandardSchemeFactory();
    private static final org.apache.thrift.scheme.SchemeFactory TUPLE_SCHEME_FACTORY = new hdfsToFiles_argsTupleSchemeFactory();

    public java.lang.String filePath; // required
    public java.lang.String exportDir; // required
    public DKFILEConf dkFileConf; // required

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements org.apache.thrift.TFieldIdEnum {
      FILE_PATH((short)1, "filePath"),
      EXPORT_DIR((short)2, "exportDir"),
      DK_FILE_CONF((short)3, "dkFileConf");

      private static final java.util.Map<java.lang.String, _Fields> byName = new java.util.HashMap<java.lang.String, _Fields>();

      static {
        for (_Fields field : java.util.EnumSet.allOf(_Fields.class)) {
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        switch(fieldId) {
          case 1: // FILE_PATH
            return FILE_PATH;
          case 2: // EXPORT_DIR
            return EXPORT_DIR;
          case 3: // DK_FILE_CONF
            return DK_FILE_CONF;
          default:
            return null;
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new java.lang.IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(java.lang.String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final java.lang.String _fieldName;

      _Fields(short thriftId, java.lang.String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public java.lang.String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments
    public static final java.util.Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
    static {
      java.util.Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new java.util.EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
      tmpMap.put(_Fields.FILE_PATH, new org.apache.thrift.meta_data.FieldMetaData("filePath", org.apache.thrift.TFieldRequirementType.DEFAULT, 
          new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
      tmpMap.put(_Fields.EXPORT_DIR, new org.apache.thrift.meta_data.FieldMetaData("exportDir", org.apache.thrift.TFieldRequirementType.DEFAULT, 
          new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
      tmpMap.put(_Fields.DK_FILE_CONF, new org.apache.thrift.meta_data.FieldMetaData("dkFileConf", org.apache.thrift.TFieldRequirementType.DEFAULT, 
          new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, DKFILEConf.class)));
      metaDataMap = java.util.Collections.unmodifiableMap(tmpMap);
      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(hdfsToFiles_args.class, metaDataMap);
    }

    public hdfsToFiles_args() {
    }

    public hdfsToFiles_args(
      java.lang.String filePath,
      java.lang.String exportDir,
      DKFILEConf dkFileConf)
    {
      this();
      this.filePath = filePath;
      this.exportDir = exportDir;
      this.dkFileConf = dkFileConf;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public hdfsToFiles_args(hdfsToFiles_args other) {
      if (other.isSetFilePath()) {
        this.filePath = other.filePath;
      }
      if (other.isSetExportDir()) {
        this.exportDir = other.exportDir;
      }
      if (other.isSetDkFileConf()) {
        this.dkFileConf = new DKFILEConf(other.dkFileConf);
      }
    }

    public hdfsToFiles_args deepCopy() {
      return new hdfsToFiles_args(this);
    }

    @Override
    public void clear() {
      this.filePath = null;
      this.exportDir = null;
      this.dkFileConf = null;
    }

    public java.lang.String getFilePath() {
      return this.filePath;
    }

    public hdfsToFiles_args setFilePath(java.lang.String filePath) {
      this.filePath = filePath;
      return this;
    }

    public void unsetFilePath() {
      this.filePath = null;
    }

    /** Returns true if field filePath is set (has been assigned a value) and false otherwise */
    public boolean isSetFilePath() {
      return this.filePath != null;
    }

    public void setFilePathIsSet(boolean value) {
      if (!value) {
        this.filePath = null;
      }
    }

    public java.lang.String getExportDir() {
      return this.exportDir;
    }

    public hdfsToFiles_args setExportDir(java.lang.String exportDir) {
      this.exportDir = exportDir;
      return this;
    }

    public void unsetExportDir() {
      this.exportDir = null;
    }

    /** Returns true if field exportDir is set (has been assigned a value) and false otherwise */
    public boolean isSetExportDir() {
      return this.exportDir != null;
    }

    public void setExportDirIsSet(boolean value) {
      if (!value) {
        this.exportDir = null;
      }
    }

    public DKFILEConf getDkFileConf() {
      return this.dkFileConf;
    }

    public hdfsToFiles_args setDkFileConf(DKFILEConf dkFileConf) {
      this.dkFileConf = dkFileConf;
      return this;
    }

    public void unsetDkFileConf() {
      this.dkFileConf = null;
    }

    /** Returns true if field dkFileConf is set (has been assigned a value) and false otherwise */
    public boolean isSetDkFileConf() {
      return this.dkFileConf != null;
    }

    public void setDkFileConfIsSet(boolean value) {
      if (!value) {
        this.dkFileConf = null;
      }
    }

    public void setFieldValue(_Fields field, java.lang.Object value) {
      switch (field) {
      case FILE_PATH:
        if (value == null) {
          unsetFilePath();
        } else {
          setFilePath((java.lang.String)value);
        }
        break;

      case EXPORT_DIR:
        if (value == null) {
          unsetExportDir();
        } else {
          setExportDir((java.lang.String)value);
        }
        break;

      case DK_FILE_CONF:
        if (value == null) {
          unsetDkFileConf();
        } else {
          setDkFileConf((DKFILEConf)value);
        }
        break;

      }
    }

    public java.lang.Object getFieldValue(_Fields field) {
      switch (field) {
      case FILE_PATH:
        return getFilePath();

      case EXPORT_DIR:
        return getExportDir();

      case DK_FILE_CONF:
        return getDkFileConf();

      }
      throw new java.lang.IllegalStateException();
    }

    /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      if (field == null) {
        throw new java.lang.IllegalArgumentException();
      }

      switch (field) {
      case FILE_PATH:
        return isSetFilePath();
      case EXPORT_DIR:
        return isSetExportDir();
      case DK_FILE_CONF:
        return isSetDkFileConf();
      }
      throw new java.lang.IllegalStateException();
    }

    @Override
    public boolean equals(java.lang.Object that) {
      if (that == null)
        return false;
      if (that instanceof hdfsToFiles_args)
        return this.equals((hdfsToFiles_args)that);
      return false;
    }

    public boolean equals(hdfsToFiles_args that) {
      if (that == null)
        return false;
      if (this == that)
        return true;

      boolean this_present_filePath = true && this.isSetFilePath();
      boolean that_present_filePath = true && that.isSetFilePath();
      if (this_present_filePath || that_present_filePath) {
        if (!(this_present_filePath && that_present_filePath))
          return false;
        if (!this.filePath.equals(that.filePath))
          return false;
      }

      boolean this_present_exportDir = true && this.isSetExportDir();
      boolean that_present_exportDir = true && that.isSetExportDir();
      if (this_present_exportDir || that_present_exportDir) {
        if (!(this_present_exportDir && that_present_exportDir))
          return false;
        if (!this.exportDir.equals(that.exportDir))
          return false;
      }

      boolean this_present_dkFileConf = true && this.isSetDkFileConf();
      boolean that_present_dkFileConf = true && that.isSetDkFileConf();
      if (this_present_dkFileConf || that_present_dkFileConf) {
        if (!(this_present_dkFileConf && that_present_dkFileConf))
          return false;
        if (!this.dkFileConf.equals(that.dkFileConf))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      int hashCode = 1;

      hashCode = hashCode * 8191 + ((isSetFilePath()) ? 131071 : 524287);
      if (isSetFilePath())
        hashCode = hashCode * 8191 + filePath.hashCode();

      hashCode = hashCode * 8191 + ((isSetExportDir()) ? 131071 : 524287);
      if (isSetExportDir())
        hashCode = hashCode * 8191 + exportDir.hashCode();

      hashCode = hashCode * 8191 + ((isSetDkFileConf()) ? 131071 : 524287);
      if (isSetDkFileConf())
        hashCode = hashCode * 8191 + dkFileConf.hashCode();

      return hashCode;
    }

    @Override
    public int compareTo(hdfsToFiles_args other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;

      lastComparison = java.lang.Boolean.valueOf(isSetFilePath()).compareTo(other.isSetFilePath());
      if (lastComparison != 0) {
        return lastComparison;
      }
      if (isSetFilePath()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.filePath, other.filePath);
        if (lastComparison != 0) {
          return lastComparison;
        }
      }
      lastComparison = java.lang.Boolean.valueOf(isSetExportDir()).compareTo(other.isSetExportDir());
      if (lastComparison != 0) {
        return lastComparison;
      }
      if (isSetExportDir()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.exportDir, other.exportDir);
        if (lastComparison != 0) {
          return lastComparison;
        }
      }
      lastComparison = java.lang.Boolean.valueOf(isSetDkFileConf()).compareTo(other.isSetDkFileConf());
      if (lastComparison != 0) {
        return lastComparison;
      }
      if (isSetDkFileConf()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.dkFileConf, other.dkFileConf);
        if (lastComparison != 0) {
          return lastComparison;
        }
      }
      return 0;
    }

    public _Fields fieldForId(int fieldId) {
      return _Fields.findByThriftId(fieldId);
    }

    public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException {
      scheme(iprot).read(iprot, this);
    }

    public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException {
      scheme(oprot).write(oprot, this);
    }

    @Override
    public java.lang.String toString() {
      java.lang.StringBuilder sb = new java.lang.StringBuilder("hdfsToFiles_args(");
      boolean first = true;

      sb.append("filePath:");
      if (this.filePath == null) {
        sb.append("null");
      } else {
        sb.append(this.filePath);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("exportDir:");
      if (this.exportDir == null) {
        sb.append("null");
      } else {
        sb.append(this.exportDir);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("dkFileConf:");
      if (this.dkFileConf == null) {
        sb.append("null");
      } else {
        sb.append(this.dkFileConf);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws org.apache.thrift.TException {
      // check for required fields
      // check for sub-struct validity
      if (dkFileConf != null) {
        dkFileConf.validate();
      }
    }

    private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
      try {
        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));
      } catch (org.apache.thrift.TException te) {
        throw new java.io.IOException(te);
      }
    }

    private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, java.lang.ClassNotFoundException {
      try {
        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));
      } catch (org.apache.thrift.TException te) {
        throw new java.io.IOException(te);
      }
    }

    private static class hdfsToFiles_argsStandardSchemeFactory implements org.apache.thrift.scheme.SchemeFactory {
      public hdfsToFiles_argsStandardScheme getScheme() {
        return new hdfsToFiles_argsStandardScheme();
      }
    }

    private static class hdfsToFiles_argsStandardScheme extends org.apache.thrift.scheme.StandardScheme<hdfsToFiles_args> {

      public void read(org.apache.thrift.protocol.TProtocol iprot, hdfsToFiles_args struct) throws org.apache.thrift.TException {
        org.apache.thrift.protocol.TField schemeField;
        iprot.readStructBegin();
        while (true)
        {
          schemeField = iprot.readFieldBegin();
          if (schemeField.type == org.apache.thrift.protocol.TType.STOP) { 
            break;
          }
          switch (schemeField.id) {
            case 1: // FILE_PATH
              if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
                struct.filePath = iprot.readString();
                struct.setFilePathIsSet(true);
              } else { 
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
              }
              break;
            case 2: // EXPORT_DIR
              if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
                struct.exportDir = iprot.readString();
                struct.setExportDirIsSet(true);
              } else { 
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
              }
              break;
            case 3: // DK_FILE_CONF
              if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
                struct.dkFileConf = new DKFILEConf();
                struct.dkFileConf.read(iprot);
                struct.setDkFileConfIsSet(true);
              } else { 
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
              }
              break;
            default:
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
          }
          iprot.readFieldEnd();
        }
        iprot.readStructEnd();

        // check for required fields of primitive type, which can't be checked in the validate method
        struct.validate();
      }

      public void write(org.apache.thrift.protocol.TProtocol oprot, hdfsToFiles_args struct) throws org.apache.thrift.TException {
        struct.validate();

        oprot.writeStructBegin(STRUCT_DESC);
        if (struct.filePath != null) {
          oprot.writeFieldBegin(FILE_PATH_FIELD_DESC);
          oprot.writeString(struct.filePath);
          oprot.writeFieldEnd();
        }
        if (struct.exportDir != null) {
          oprot.writeFieldBegin(EXPORT_DIR_FIELD_DESC);
          oprot.writeString(struct.exportDir);
          oprot.writeFieldEnd();
        }
        if (struct.dkFileConf != null) {
          oprot.writeFieldBegin(DK_FILE_CONF_FIELD_DESC);
          struct.dkFileConf.write(oprot);
          oprot.writeFieldEnd();
        }
        oprot.writeFieldStop();
        oprot.writeStructEnd();
      }

    }

    private static class hdfsToFiles_argsTupleSchemeFactory implements org.apache.thrift.scheme.SchemeFactory {
      public hdfsToFiles_argsTupleScheme getScheme() {
        return new hdfsToFiles_argsTupleScheme();
      }
    }

    private static class hdfsToFiles_argsTupleScheme extends org.apache.thrift.scheme.TupleScheme<hdfsToFiles_args> {

      @Override
      public void write(org.apache.thrift.protocol.TProtocol prot, hdfsToFiles_args struct) throws org.apache.thrift.TException {
        org.apache.thrift.protocol.TTupleProtocol oprot = (org.apache.thrift.protocol.TTupleProtocol) prot;
        java.util.BitSet optionals = new java.util.BitSet();
        if (struct.isSetFilePath()) {
          optionals.set(0);
        }
        if (struct.isSetExportDir()) {
          optionals.set(1);
        }
        if (struct.isSetDkFileConf()) {
          optionals.set(2);
        }
        oprot.writeBitSet(optionals, 3);
        if (struct.isSetFilePath()) {
          oprot.writeString(struct.filePath);
        }
        if (struct.isSetExportDir()) {
          oprot.writeString(struct.exportDir);
        }
        if (struct.isSetDkFileConf()) {
          struct.dkFileConf.write(oprot);
        }
      }

      @Override
      public void read(org.apache.thrift.protocol.TProtocol prot, hdfsToFiles_args struct) throws org.apache.thrift.TException {
        org.apache.thrift.protocol.TTupleProtocol iprot = (org.apache.thrift.protocol.TTupleProtocol) prot;
        java.util.BitSet incoming = iprot.readBitSet(3);
        if (incoming.get(0)) {
          struct.filePath = iprot.readString();
          struct.setFilePathIsSet(true);
        }
        if (incoming.get(1)) {
          struct.exportDir = iprot.readString();
          struct.setExportDirIsSet(true);
        }
        if (incoming.get(2)) {
          struct.dkFileConf = new DKFILEConf();
          struct.dkFileConf.read(iprot);
          struct.setDkFileConfIsSet(true);
        }
      }
    }

    private static <S extends org.apache.thrift.scheme.IScheme> S scheme(org.apache.thrift.protocol.TProtocol proto) {
      return (org.apache.thrift.scheme.StandardScheme.class.equals(proto.getScheme()) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY).getScheme();
    }
  }

  public static class hdfsToFiles_result implements org.apache.thrift.TBase<hdfsToFiles_result, hdfsToFiles_result._Fields>, java.io.Serializable, Cloneable, Comparable<hdfsToFiles_result>   {
    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("hdfsToFiles_result");

    private static final org.apache.thrift.protocol.TField SUCCESS_FIELD_DESC = new org.apache.thrift.protocol.TField("success", org.apache.thrift.protocol.TType.STRUCT, (short)0);

    private static final org.apache.thrift.scheme.SchemeFactory STANDARD_SCHEME_FACTORY = new hdfsToFiles_resultStandardSchemeFactory();
    private static final org.apache.thrift.scheme.SchemeFactory TUPLE_SCHEME_FACTORY = new hdfsToFiles_resultTupleSchemeFactory();

    public ResultEntity success; // required

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements org.apache.thrift.TFieldIdEnum {
      SUCCESS((short)0, "success");

      private static final java.util.Map<java.lang.String, _Fields> byName = new java.util.HashMap<java.lang.String, _Fields>();

      static {
        for (_Fields field : java.util.EnumSet.allOf(_Fields.class)) {
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        switch(fieldId) {
          case 0: // SUCCESS
            return SUCCESS;
          default:
            return null;
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new java.lang.IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(java.lang.String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final java.lang.String _fieldName;

      _Fields(short thriftId, java.lang.String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public java.lang.String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments
    public static final java.util.Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
    static {
      java.util.Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new java.util.EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
      tmpMap.put(_Fields.SUCCESS, new org.apache.thrift.meta_data.FieldMetaData("success", org.apache.thrift.TFieldRequirementType.DEFAULT, 
          new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, ResultEntity.class)));
      metaDataMap = java.util.Collections.unmodifiableMap(tmpMap);
      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(hdfsToFiles_result.class, metaDataMap);
    }

    public hdfsToFiles_result() {
    }

    public hdfsToFiles_result(
      ResultEntity success)
    {
      this();
      this.success = success;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public hdfsToFiles_result(hdfsToFiles_result other) {
      if (other.isSetSuccess()) {
        this.success = new ResultEntity(other.success);
      }
    }

    public hdfsToFiles_result deepCopy() {
      return new hdfsToFiles_result(this);
    }

    @Override
    public void clear() {
      this.success = null;
    }

    public ResultEntity getSuccess() {
      return this.success;
    }

    public hdfsToFiles_result setSuccess(ResultEntity success) {
      this.success = success;
      return this;
    }

    public void unsetSuccess() {
      this.success = null;
    }

    /** Returns true if field success is set (has been assigned a value) and false otherwise */
    public boolean isSetSuccess() {
      return this.success != null;
    }

    public void setSuccessIsSet(boolean value) {
      if (!value) {
        this.success = null;
      }
    }

    public void setFieldValue(_Fields field, java.lang.Object value) {
      switch (field) {
      case SUCCESS:
        if (value == null) {
          unsetSuccess();
        } else {
          setSuccess((ResultEntity)value);
        }
        break;

      }
    }

    public java.lang.Object getFieldValue(_Fields field) {
      switch (field) {
      case SUCCESS:
        return getSuccess();

      }
      throw new java.lang.IllegalStateException();
    }

    /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      if (field == null) {
        throw new java.lang.IllegalArgumentException();
      }

      switch (field) {
      case SUCCESS:
        return isSetSuccess();
      }
      throw new java.lang.IllegalStateException();
    }

    @Override
    public boolean equals(java.lang.Object that) {
      if (that == null)
        return false;
      if (that instanceof hdfsToFiles_result)
        return this.equals((hdfsToFiles_result)that);
      return false;
    }

    public boolean equals(hdfsToFiles_result that) {
      if (that == null)
        return false;
      if (this == that)
        return true;

      boolean this_present_success = true && this.isSetSuccess();
      boolean that_present_success = true && that.isSetSuccess();
      if (this_present_success || that_present_success) {
        if (!(this_present_success && that_present_success))
          return false;
        if (!this.success.equals(that.success))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      int hashCode = 1;

      hashCode = hashCode * 8191 + ((isSetSuccess()) ? 131071 : 524287);
      if (isSetSuccess())
        hashCode = hashCode * 8191 + success.hashCode();

      return hashCode;
    }

    @Override
    public int compareTo(hdfsToFiles_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;

      lastComparison = java.lang.Boolean.valueOf(isSetSuccess()).compareTo(other.isSetSuccess());
      if (lastComparison != 0) {
        return lastComparison;
      }
      if (isSetSuccess()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.success, other.success);
        if (lastComparison != 0) {
          return lastComparison;
        }
      }
      return 0;
    }

    public _Fields fieldForId(int fieldId) {
      return _Fields.findByThriftId(fieldId);
    }

    public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException {
      scheme(iprot).read(iprot, this);
    }

    public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException {
      scheme(oprot).write(oprot, this);
      }

    @Override
    public java.lang.String toString() {
      java.lang.StringBuilder sb = new java.lang.StringBuilder("hdfsToFiles_result(");
      boolean first = true;

      sb.append("success:");
      if (this.success == null) {
        sb.append("null");
      } else {
        sb.append(this.success);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws org.apache.thrift.TException {
      // check for required fields
      // check for sub-struct validity
      if (success != null) {
        success.validate();
      }
    }

    private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
      try {
        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));
      } catch (org.apache.thrift.TException te) {
        throw new java.io.IOException(te);
      }
    }

    private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, java.lang.ClassNotFoundException {
      try {
        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));
      } catch (org.apache.thrift.TException te) {
        throw new java.io.IOException(te);
      }
    }

    private static class hdfsToFiles_resultStandardSchemeFactory implements org.apache.thrift.scheme.SchemeFactory {
      public hdfsToFiles_resultStandardScheme getScheme() {
        return new hdfsToFiles_resultStandardScheme();
      }
    }

    private static class hdfsToFiles_resultStandardScheme extends org.apache.thrift.scheme.StandardScheme<hdfsToFiles_result> {

      public void read(org.apache.thrift.protocol.TProtocol iprot, hdfsToFiles_result struct) throws org.apache.thrift.TException {
        org.apache.thrift.protocol.TField schemeField;
        iprot.readStructBegin();
        while (true)
        {
          schemeField = iprot.readFieldBegin();
          if (schemeField.type == org.apache.thrift.protocol.TType.STOP) { 
            break;
          }
          switch (schemeField.id) {
            case 0: // SUCCESS
              if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
                struct.success = new ResultEntity();
                struct.success.read(iprot);
                struct.setSuccessIsSet(true);
              } else { 
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
              }
              break;
            default:
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
          }
          iprot.readFieldEnd();
        }
        iprot.readStructEnd();

        // check for required fields of primitive type, which can't be checked in the validate method
        struct.validate();
      }

      public void write(org.apache.thrift.protocol.TProtocol oprot, hdfsToFiles_result struct) throws org.apache.thrift.TException {
        struct.validate();

        oprot.writeStructBegin(STRUCT_DESC);
        if (struct.success != null) {
          oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
          struct.success.write(oprot);
          oprot.writeFieldEnd();
        }
        oprot.writeFieldStop();
        oprot.writeStructEnd();
      }

    }

    private static class hdfsToFiles_resultTupleSchemeFactory implements org.apache.thrift.scheme.SchemeFactory {
      public hdfsToFiles_resultTupleScheme getScheme() {
        return new hdfsToFiles_resultTupleScheme();
      }
    }

    private static class hdfsToFiles_resultTupleScheme extends org.apache.thrift.scheme.TupleScheme<hdfsToFiles_result> {

      @Override
      public void write(org.apache.thrift.protocol.TProtocol prot, hdfsToFiles_result struct) throws org.apache.thrift.TException {
        org.apache.thrift.protocol.TTupleProtocol oprot = (org.apache.thrift.protocol.TTupleProtocol) prot;
        java.util.BitSet optionals = new java.util.BitSet();
        if (struct.isSetSuccess()) {
          optionals.set(0);
        }
        oprot.writeBitSet(optionals, 1);
        if (struct.isSetSuccess()) {
          struct.success.write(oprot);
        }
      }

      @Override
      public void read(org.apache.thrift.protocol.TProtocol prot, hdfsToFiles_result struct) throws org.apache.thrift.TException {
        org.apache.thrift.protocol.TTupleProtocol iprot = (org.apache.thrift.protocol.TTupleProtocol) prot;
        java.util.BitSet incoming = iprot.readBitSet(1);
        if (incoming.get(0)) {
          struct.success = new ResultEntity();
          struct.success.read(iprot);
          struct.setSuccessIsSet(true);
        }
      }
    }

    private static <S extends org.apache.thrift.scheme.IScheme> S scheme(org.apache.thrift.protocol.TProtocol proto) {
      return (org.apache.thrift.scheme.StandardScheme.class.equals(proto.getScheme()) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY).getScheme();
    }
  }

}
