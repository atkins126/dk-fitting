/**
 * Autogenerated by Thrift Compiler (0.11.0)
 *
 * DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING
 *  @generated
 */
package com.dksou.fitting.datasource.service;

@SuppressWarnings({"cast", "rawtypes", "serial", "unchecked", "unused"})
@javax.annotation.Generated(value = "Autogenerated by Thrift Compiler (0.11.0)", date = "2019-06-21")
public class DKDBOutput {

  public interface Iface {

    /**
     * @param connect       JDBC连接字符串
     * @param username      数据库用户名
     * @param password      数据库密码
     * @param table         关系数据库表名，数据导入该表中
     * @param exportDir     导出的HDFS路径
     * @param writeMode     数据导出到数据库的模式 0：INSERT模式导出（将数据转换成Insert语句添加到数据库表中，注意表的一些约束如关键字唯一等）
     *                      1：UPDATE模式导出（updateonly仅更新原有数据，不会插入新数据） 2：UPDATE模式导出（allowinsert，更新原有数据且插入新数据）
     * @param updateKey     根据更新的列，多个列用英文逗号分隔
     * @param numMappers    启动的map来并行导入数据，默认是4个，最好不要将数字设置为高于集群的节点数
     * @param fileSeparator 指定各字段的分隔符，默认为英文逗号
     * @param extra         额外的合法参数，参考sqoop官网（格式：--xxx --xxx）
     * @param dkdbConf      dkdb服务的配置项，详见文档
     * @return
     * 
     * @param connect
     * @param username
     * @param password
     * @param table
     * @param exportDir
     * @param writeMode
     * @param updateKey
     * @param numMappers
     * @param fileSeparator
     * @param extra
     * @param dkdbConf
     */
    public ResultEntity hdfsToRdbms(java.lang.String connect, java.lang.String username, java.lang.String password, java.lang.String table, java.lang.String exportDir, int writeMode, java.lang.String updateKey, java.lang.String numMappers, java.lang.String fileSeparator, java.lang.String extra, DKDBConf dkdbConf) throws org.apache.thrift.TException;

  }

  public interface AsyncIface {

    public void hdfsToRdbms(java.lang.String connect, java.lang.String username, java.lang.String password, java.lang.String table, java.lang.String exportDir, int writeMode, java.lang.String updateKey, java.lang.String numMappers, java.lang.String fileSeparator, java.lang.String extra, DKDBConf dkdbConf, org.apache.thrift.async.AsyncMethodCallback<ResultEntity> resultHandler) throws org.apache.thrift.TException;

  }

  public static class Client extends org.apache.thrift.TServiceClient implements Iface {
    public static class Factory implements org.apache.thrift.TServiceClientFactory<Client> {
      public Factory() {}
      public Client getClient(org.apache.thrift.protocol.TProtocol prot) {
        return new Client(prot);
      }
      public Client getClient(org.apache.thrift.protocol.TProtocol iprot, org.apache.thrift.protocol.TProtocol oprot) {
        return new Client(iprot, oprot);
      }
    }

    public Client(org.apache.thrift.protocol.TProtocol prot)
    {
      super(prot, prot);
    }

    public Client(org.apache.thrift.protocol.TProtocol iprot, org.apache.thrift.protocol.TProtocol oprot) {
      super(iprot, oprot);
    }

    public ResultEntity hdfsToRdbms(java.lang.String connect, java.lang.String username, java.lang.String password, java.lang.String table, java.lang.String exportDir, int writeMode, java.lang.String updateKey, java.lang.String numMappers, java.lang.String fileSeparator, java.lang.String extra, DKDBConf dkdbConf) throws org.apache.thrift.TException
    {
      send_hdfsToRdbms(connect, username, password, table, exportDir, writeMode, updateKey, numMappers, fileSeparator, extra, dkdbConf);
      return recv_hdfsToRdbms();
    }

    public void send_hdfsToRdbms(java.lang.String connect, java.lang.String username, java.lang.String password, java.lang.String table, java.lang.String exportDir, int writeMode, java.lang.String updateKey, java.lang.String numMappers, java.lang.String fileSeparator, java.lang.String extra, DKDBConf dkdbConf) throws org.apache.thrift.TException
    {
      hdfsToRdbms_args args = new hdfsToRdbms_args();
      args.setConnect(connect);
      args.setUsername(username);
      args.setPassword(password);
      args.setTable(table);
      args.setExportDir(exportDir);
      args.setWriteMode(writeMode);
      args.setUpdateKey(updateKey);
      args.setNumMappers(numMappers);
      args.setFileSeparator(fileSeparator);
      args.setExtra(extra);
      args.setDkdbConf(dkdbConf);
      sendBase("hdfsToRdbms", args);
    }

    public ResultEntity recv_hdfsToRdbms() throws org.apache.thrift.TException
    {
      hdfsToRdbms_result result = new hdfsToRdbms_result();
      receiveBase(result, "hdfsToRdbms");
      if (result.isSetSuccess()) {
        return result.success;
      }
      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, "hdfsToRdbms failed: unknown result");
    }

  }
  public static class AsyncClient extends org.apache.thrift.async.TAsyncClient implements AsyncIface {
    public static class Factory implements org.apache.thrift.async.TAsyncClientFactory<AsyncClient> {
      private org.apache.thrift.async.TAsyncClientManager clientManager;
      private org.apache.thrift.protocol.TProtocolFactory protocolFactory;
      public Factory(org.apache.thrift.async.TAsyncClientManager clientManager, org.apache.thrift.protocol.TProtocolFactory protocolFactory) {
        this.clientManager = clientManager;
        this.protocolFactory = protocolFactory;
      }
      public AsyncClient getAsyncClient(org.apache.thrift.transport.TNonblockingTransport transport) {
        return new AsyncClient(protocolFactory, clientManager, transport);
      }
    }

    public AsyncClient(org.apache.thrift.protocol.TProtocolFactory protocolFactory, org.apache.thrift.async.TAsyncClientManager clientManager, org.apache.thrift.transport.TNonblockingTransport transport) {
      super(protocolFactory, clientManager, transport);
    }

    public void hdfsToRdbms(java.lang.String connect, java.lang.String username, java.lang.String password, java.lang.String table, java.lang.String exportDir, int writeMode, java.lang.String updateKey, java.lang.String numMappers, java.lang.String fileSeparator, java.lang.String extra, DKDBConf dkdbConf, org.apache.thrift.async.AsyncMethodCallback<ResultEntity> resultHandler) throws org.apache.thrift.TException {
      checkReady();
      hdfsToRdbms_call method_call = new hdfsToRdbms_call(connect, username, password, table, exportDir, writeMode, updateKey, numMappers, fileSeparator, extra, dkdbConf, resultHandler, this, ___protocolFactory, ___transport);
      this.___currentMethod = method_call;
      ___manager.call(method_call);
    }

    public static class hdfsToRdbms_call extends org.apache.thrift.async.TAsyncMethodCall<ResultEntity> {
      private java.lang.String connect;
      private java.lang.String username;
      private java.lang.String password;
      private java.lang.String table;
      private java.lang.String exportDir;
      private int writeMode;
      private java.lang.String updateKey;
      private java.lang.String numMappers;
      private java.lang.String fileSeparator;
      private java.lang.String extra;
      private DKDBConf dkdbConf;
      public hdfsToRdbms_call(java.lang.String connect, java.lang.String username, java.lang.String password, java.lang.String table, java.lang.String exportDir, int writeMode, java.lang.String updateKey, java.lang.String numMappers, java.lang.String fileSeparator, java.lang.String extra, DKDBConf dkdbConf, org.apache.thrift.async.AsyncMethodCallback<ResultEntity> resultHandler, org.apache.thrift.async.TAsyncClient client, org.apache.thrift.protocol.TProtocolFactory protocolFactory, org.apache.thrift.transport.TNonblockingTransport transport) throws org.apache.thrift.TException {
        super(client, protocolFactory, transport, resultHandler, false);
        this.connect = connect;
        this.username = username;
        this.password = password;
        this.table = table;
        this.exportDir = exportDir;
        this.writeMode = writeMode;
        this.updateKey = updateKey;
        this.numMappers = numMappers;
        this.fileSeparator = fileSeparator;
        this.extra = extra;
        this.dkdbConf = dkdbConf;
      }

      public void write_args(org.apache.thrift.protocol.TProtocol prot) throws org.apache.thrift.TException {
        prot.writeMessageBegin(new org.apache.thrift.protocol.TMessage("hdfsToRdbms", org.apache.thrift.protocol.TMessageType.CALL, 0));
        hdfsToRdbms_args args = new hdfsToRdbms_args();
        args.setConnect(connect);
        args.setUsername(username);
        args.setPassword(password);
        args.setTable(table);
        args.setExportDir(exportDir);
        args.setWriteMode(writeMode);
        args.setUpdateKey(updateKey);
        args.setNumMappers(numMappers);
        args.setFileSeparator(fileSeparator);
        args.setExtra(extra);
        args.setDkdbConf(dkdbConf);
        args.write(prot);
        prot.writeMessageEnd();
      }

      public ResultEntity getResult() throws org.apache.thrift.TException {
        if (getState() != org.apache.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {
          throw new java.lang.IllegalStateException("Method call not finished!");
        }
        org.apache.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());
        org.apache.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);
        return (new Client(prot)).recv_hdfsToRdbms();
      }
    }

  }

  public static class Processor<I extends Iface> extends org.apache.thrift.TBaseProcessor<I> implements org.apache.thrift.TProcessor {
    private static final org.slf4j.Logger _LOGGER = org.slf4j.LoggerFactory.getLogger(Processor.class.getName());
    public Processor(I iface) {
      super(iface, getProcessMap(new java.util.HashMap<java.lang.String, org.apache.thrift.ProcessFunction<I, ? extends org.apache.thrift.TBase>>()));
    }

    protected Processor(I iface, java.util.Map<java.lang.String, org.apache.thrift.ProcessFunction<I, ? extends org.apache.thrift.TBase>> processMap) {
      super(iface, getProcessMap(processMap));
    }

    private static <I extends Iface> java.util.Map<java.lang.String,  org.apache.thrift.ProcessFunction<I, ? extends org.apache.thrift.TBase>> getProcessMap(java.util.Map<java.lang.String, org.apache.thrift.ProcessFunction<I, ? extends  org.apache.thrift.TBase>> processMap) {
      processMap.put("hdfsToRdbms", new hdfsToRdbms());
      return processMap;
    }

    public static class hdfsToRdbms<I extends Iface> extends org.apache.thrift.ProcessFunction<I, hdfsToRdbms_args> {
      public hdfsToRdbms() {
        super("hdfsToRdbms");
      }

      public hdfsToRdbms_args getEmptyArgsInstance() {
        return new hdfsToRdbms_args();
      }

      protected boolean isOneway() {
        return false;
      }

      @Override
      protected boolean handleRuntimeExceptions() {
        return false;
      }

      public hdfsToRdbms_result getResult(I iface, hdfsToRdbms_args args) throws org.apache.thrift.TException {
        hdfsToRdbms_result result = new hdfsToRdbms_result();
        result.success = iface.hdfsToRdbms(args.connect, args.username, args.password, args.table, args.exportDir, args.writeMode, args.updateKey, args.numMappers, args.fileSeparator, args.extra, args.dkdbConf);
        return result;
      }
    }

  }

  public static class AsyncProcessor<I extends AsyncIface> extends org.apache.thrift.TBaseAsyncProcessor<I> {
    private static final org.slf4j.Logger _LOGGER = org.slf4j.LoggerFactory.getLogger(AsyncProcessor.class.getName());
    public AsyncProcessor(I iface) {
      super(iface, getProcessMap(new java.util.HashMap<java.lang.String, org.apache.thrift.AsyncProcessFunction<I, ? extends org.apache.thrift.TBase, ?>>()));
    }

    protected AsyncProcessor(I iface, java.util.Map<java.lang.String,  org.apache.thrift.AsyncProcessFunction<I, ? extends  org.apache.thrift.TBase, ?>> processMap) {
      super(iface, getProcessMap(processMap));
    }

    private static <I extends AsyncIface> java.util.Map<java.lang.String,  org.apache.thrift.AsyncProcessFunction<I, ? extends  org.apache.thrift.TBase,?>> getProcessMap(java.util.Map<java.lang.String,  org.apache.thrift.AsyncProcessFunction<I, ? extends  org.apache.thrift.TBase, ?>> processMap) {
      processMap.put("hdfsToRdbms", new hdfsToRdbms());
      return processMap;
    }

    public static class hdfsToRdbms<I extends AsyncIface> extends org.apache.thrift.AsyncProcessFunction<I, hdfsToRdbms_args, ResultEntity> {
      public hdfsToRdbms() {
        super("hdfsToRdbms");
      }

      public hdfsToRdbms_args getEmptyArgsInstance() {
        return new hdfsToRdbms_args();
      }

      public org.apache.thrift.async.AsyncMethodCallback<ResultEntity> getResultHandler(final org.apache.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {
        final org.apache.thrift.AsyncProcessFunction fcall = this;
        return new org.apache.thrift.async.AsyncMethodCallback<ResultEntity>() { 
          public void onComplete(ResultEntity o) {
            hdfsToRdbms_result result = new hdfsToRdbms_result();
            result.success = o;
            try {
              fcall.sendResponse(fb, result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);
            } catch (org.apache.thrift.transport.TTransportException e) {
              _LOGGER.error("TTransportException writing to internal frame buffer", e);
              fb.close();
            } catch (java.lang.Exception e) {
              _LOGGER.error("Exception writing to internal frame buffer", e);
              onError(e);
            }
          }
          public void onError(java.lang.Exception e) {
            byte msgType = org.apache.thrift.protocol.TMessageType.REPLY;
            org.apache.thrift.TSerializable msg;
            hdfsToRdbms_result result = new hdfsToRdbms_result();
            if (e instanceof org.apache.thrift.transport.TTransportException) {
              _LOGGER.error("TTransportException inside handler", e);
              fb.close();
              return;
            } else if (e instanceof org.apache.thrift.TApplicationException) {
              _LOGGER.error("TApplicationException inside handler", e);
              msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;
              msg = (org.apache.thrift.TApplicationException)e;
            } else {
              _LOGGER.error("Exception inside handler", e);
              msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;
              msg = new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());
            }
            try {
              fcall.sendResponse(fb,msg,msgType,seqid);
            } catch (java.lang.Exception ex) {
              _LOGGER.error("Exception writing to internal frame buffer", ex);
              fb.close();
            }
          }
        };
      }

      protected boolean isOneway() {
        return false;
      }

      public void start(I iface, hdfsToRdbms_args args, org.apache.thrift.async.AsyncMethodCallback<ResultEntity> resultHandler) throws org.apache.thrift.TException {
        iface.hdfsToRdbms(args.connect, args.username, args.password, args.table, args.exportDir, args.writeMode, args.updateKey, args.numMappers, args.fileSeparator, args.extra, args.dkdbConf,resultHandler);
      }
    }

  }

  public static class hdfsToRdbms_args implements org.apache.thrift.TBase<hdfsToRdbms_args, hdfsToRdbms_args._Fields>, java.io.Serializable, Cloneable, Comparable<hdfsToRdbms_args>   {
    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("hdfsToRdbms_args");

    private static final org.apache.thrift.protocol.TField CONNECT_FIELD_DESC = new org.apache.thrift.protocol.TField("connect", org.apache.thrift.protocol.TType.STRING, (short)1);
    private static final org.apache.thrift.protocol.TField USERNAME_FIELD_DESC = new org.apache.thrift.protocol.TField("username", org.apache.thrift.protocol.TType.STRING, (short)2);
    private static final org.apache.thrift.protocol.TField PASSWORD_FIELD_DESC = new org.apache.thrift.protocol.TField("password", org.apache.thrift.protocol.TType.STRING, (short)3);
    private static final org.apache.thrift.protocol.TField TABLE_FIELD_DESC = new org.apache.thrift.protocol.TField("table", org.apache.thrift.protocol.TType.STRING, (short)4);
    private static final org.apache.thrift.protocol.TField EXPORT_DIR_FIELD_DESC = new org.apache.thrift.protocol.TField("exportDir", org.apache.thrift.protocol.TType.STRING, (short)5);
    private static final org.apache.thrift.protocol.TField WRITE_MODE_FIELD_DESC = new org.apache.thrift.protocol.TField("writeMode", org.apache.thrift.protocol.TType.I32, (short)6);
    private static final org.apache.thrift.protocol.TField UPDATE_KEY_FIELD_DESC = new org.apache.thrift.protocol.TField("updateKey", org.apache.thrift.protocol.TType.STRING, (short)7);
    private static final org.apache.thrift.protocol.TField NUM_MAPPERS_FIELD_DESC = new org.apache.thrift.protocol.TField("numMappers", org.apache.thrift.protocol.TType.STRING, (short)8);
    private static final org.apache.thrift.protocol.TField FILE_SEPARATOR_FIELD_DESC = new org.apache.thrift.protocol.TField("fileSeparator", org.apache.thrift.protocol.TType.STRING, (short)9);
    private static final org.apache.thrift.protocol.TField EXTRA_FIELD_DESC = new org.apache.thrift.protocol.TField("extra", org.apache.thrift.protocol.TType.STRING, (short)10);
    private static final org.apache.thrift.protocol.TField DKDB_CONF_FIELD_DESC = new org.apache.thrift.protocol.TField("dkdbConf", org.apache.thrift.protocol.TType.STRUCT, (short)11);

    private static final org.apache.thrift.scheme.SchemeFactory STANDARD_SCHEME_FACTORY = new hdfsToRdbms_argsStandardSchemeFactory();
    private static final org.apache.thrift.scheme.SchemeFactory TUPLE_SCHEME_FACTORY = new hdfsToRdbms_argsTupleSchemeFactory();

    public java.lang.String connect; // required
    public java.lang.String username; // required
    public java.lang.String password; // required
    public java.lang.String table; // required
    public java.lang.String exportDir; // required
    public int writeMode; // required
    public java.lang.String updateKey; // required
    public java.lang.String numMappers; // required
    public java.lang.String fileSeparator; // required
    public java.lang.String extra; // required
    public DKDBConf dkdbConf; // required

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements org.apache.thrift.TFieldIdEnum {
      CONNECT((short)1, "connect"),
      USERNAME((short)2, "username"),
      PASSWORD((short)3, "password"),
      TABLE((short)4, "table"),
      EXPORT_DIR((short)5, "exportDir"),
      WRITE_MODE((short)6, "writeMode"),
      UPDATE_KEY((short)7, "updateKey"),
      NUM_MAPPERS((short)8, "numMappers"),
      FILE_SEPARATOR((short)9, "fileSeparator"),
      EXTRA((short)10, "extra"),
      DKDB_CONF((short)11, "dkdbConf");

      private static final java.util.Map<java.lang.String, _Fields> byName = new java.util.HashMap<java.lang.String, _Fields>();

      static {
        for (_Fields field : java.util.EnumSet.allOf(_Fields.class)) {
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        switch(fieldId) {
          case 1: // CONNECT
            return CONNECT;
          case 2: // USERNAME
            return USERNAME;
          case 3: // PASSWORD
            return PASSWORD;
          case 4: // TABLE
            return TABLE;
          case 5: // EXPORT_DIR
            return EXPORT_DIR;
          case 6: // WRITE_MODE
            return WRITE_MODE;
          case 7: // UPDATE_KEY
            return UPDATE_KEY;
          case 8: // NUM_MAPPERS
            return NUM_MAPPERS;
          case 9: // FILE_SEPARATOR
            return FILE_SEPARATOR;
          case 10: // EXTRA
            return EXTRA;
          case 11: // DKDB_CONF
            return DKDB_CONF;
          default:
            return null;
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new java.lang.IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(java.lang.String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final java.lang.String _fieldName;

      _Fields(short thriftId, java.lang.String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public java.lang.String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments
    private static final int __WRITEMODE_ISSET_ID = 0;
    private byte __isset_bitfield = 0;
    public static final java.util.Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
    static {
      java.util.Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new java.util.EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
      tmpMap.put(_Fields.CONNECT, new org.apache.thrift.meta_data.FieldMetaData("connect", org.apache.thrift.TFieldRequirementType.DEFAULT, 
          new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
      tmpMap.put(_Fields.USERNAME, new org.apache.thrift.meta_data.FieldMetaData("username", org.apache.thrift.TFieldRequirementType.DEFAULT, 
          new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
      tmpMap.put(_Fields.PASSWORD, new org.apache.thrift.meta_data.FieldMetaData("password", org.apache.thrift.TFieldRequirementType.DEFAULT, 
          new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
      tmpMap.put(_Fields.TABLE, new org.apache.thrift.meta_data.FieldMetaData("table", org.apache.thrift.TFieldRequirementType.DEFAULT, 
          new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
      tmpMap.put(_Fields.EXPORT_DIR, new org.apache.thrift.meta_data.FieldMetaData("exportDir", org.apache.thrift.TFieldRequirementType.DEFAULT, 
          new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
      tmpMap.put(_Fields.WRITE_MODE, new org.apache.thrift.meta_data.FieldMetaData("writeMode", org.apache.thrift.TFieldRequirementType.DEFAULT, 
          new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.I32)));
      tmpMap.put(_Fields.UPDATE_KEY, new org.apache.thrift.meta_data.FieldMetaData("updateKey", org.apache.thrift.TFieldRequirementType.DEFAULT, 
          new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
      tmpMap.put(_Fields.NUM_MAPPERS, new org.apache.thrift.meta_data.FieldMetaData("numMappers", org.apache.thrift.TFieldRequirementType.DEFAULT, 
          new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
      tmpMap.put(_Fields.FILE_SEPARATOR, new org.apache.thrift.meta_data.FieldMetaData("fileSeparator", org.apache.thrift.TFieldRequirementType.DEFAULT, 
          new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
      tmpMap.put(_Fields.EXTRA, new org.apache.thrift.meta_data.FieldMetaData("extra", org.apache.thrift.TFieldRequirementType.DEFAULT, 
          new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
      tmpMap.put(_Fields.DKDB_CONF, new org.apache.thrift.meta_data.FieldMetaData("dkdbConf", org.apache.thrift.TFieldRequirementType.DEFAULT, 
          new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, DKDBConf.class)));
      metaDataMap = java.util.Collections.unmodifiableMap(tmpMap);
      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(hdfsToRdbms_args.class, metaDataMap);
    }

    public hdfsToRdbms_args() {
    }

    public hdfsToRdbms_args(
      java.lang.String connect,
      java.lang.String username,
      java.lang.String password,
      java.lang.String table,
      java.lang.String exportDir,
      int writeMode,
      java.lang.String updateKey,
      java.lang.String numMappers,
      java.lang.String fileSeparator,
      java.lang.String extra,
      DKDBConf dkdbConf)
    {
      this();
      this.connect = connect;
      this.username = username;
      this.password = password;
      this.table = table;
      this.exportDir = exportDir;
      this.writeMode = writeMode;
      setWriteModeIsSet(true);
      this.updateKey = updateKey;
      this.numMappers = numMappers;
      this.fileSeparator = fileSeparator;
      this.extra = extra;
      this.dkdbConf = dkdbConf;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public hdfsToRdbms_args(hdfsToRdbms_args other) {
      __isset_bitfield = other.__isset_bitfield;
      if (other.isSetConnect()) {
        this.connect = other.connect;
      }
      if (other.isSetUsername()) {
        this.username = other.username;
      }
      if (other.isSetPassword()) {
        this.password = other.password;
      }
      if (other.isSetTable()) {
        this.table = other.table;
      }
      if (other.isSetExportDir()) {
        this.exportDir = other.exportDir;
      }
      this.writeMode = other.writeMode;
      if (other.isSetUpdateKey()) {
        this.updateKey = other.updateKey;
      }
      if (other.isSetNumMappers()) {
        this.numMappers = other.numMappers;
      }
      if (other.isSetFileSeparator()) {
        this.fileSeparator = other.fileSeparator;
      }
      if (other.isSetExtra()) {
        this.extra = other.extra;
      }
      if (other.isSetDkdbConf()) {
        this.dkdbConf = new DKDBConf(other.dkdbConf);
      }
    }

    public hdfsToRdbms_args deepCopy() {
      return new hdfsToRdbms_args(this);
    }

    @Override
    public void clear() {
      this.connect = null;
      this.username = null;
      this.password = null;
      this.table = null;
      this.exportDir = null;
      setWriteModeIsSet(false);
      this.writeMode = 0;
      this.updateKey = null;
      this.numMappers = null;
      this.fileSeparator = null;
      this.extra = null;
      this.dkdbConf = null;
    }

    public java.lang.String getConnect() {
      return this.connect;
    }

    public hdfsToRdbms_args setConnect(java.lang.String connect) {
      this.connect = connect;
      return this;
    }

    public void unsetConnect() {
      this.connect = null;
    }

    /** Returns true if field connect is set (has been assigned a value) and false otherwise */
    public boolean isSetConnect() {
      return this.connect != null;
    }

    public void setConnectIsSet(boolean value) {
      if (!value) {
        this.connect = null;
      }
    }

    public java.lang.String getUsername() {
      return this.username;
    }

    public hdfsToRdbms_args setUsername(java.lang.String username) {
      this.username = username;
      return this;
    }

    public void unsetUsername() {
      this.username = null;
    }

    /** Returns true if field username is set (has been assigned a value) and false otherwise */
    public boolean isSetUsername() {
      return this.username != null;
    }

    public void setUsernameIsSet(boolean value) {
      if (!value) {
        this.username = null;
      }
    }

    public java.lang.String getPassword() {
      return this.password;
    }

    public hdfsToRdbms_args setPassword(java.lang.String password) {
      this.password = password;
      return this;
    }

    public void unsetPassword() {
      this.password = null;
    }

    /** Returns true if field password is set (has been assigned a value) and false otherwise */
    public boolean isSetPassword() {
      return this.password != null;
    }

    public void setPasswordIsSet(boolean value) {
      if (!value) {
        this.password = null;
      }
    }

    public java.lang.String getTable() {
      return this.table;
    }

    public hdfsToRdbms_args setTable(java.lang.String table) {
      this.table = table;
      return this;
    }

    public void unsetTable() {
      this.table = null;
    }

    /** Returns true if field table is set (has been assigned a value) and false otherwise */
    public boolean isSetTable() {
      return this.table != null;
    }

    public void setTableIsSet(boolean value) {
      if (!value) {
        this.table = null;
      }
    }

    public java.lang.String getExportDir() {
      return this.exportDir;
    }

    public hdfsToRdbms_args setExportDir(java.lang.String exportDir) {
      this.exportDir = exportDir;
      return this;
    }

    public void unsetExportDir() {
      this.exportDir = null;
    }

    /** Returns true if field exportDir is set (has been assigned a value) and false otherwise */
    public boolean isSetExportDir() {
      return this.exportDir != null;
    }

    public void setExportDirIsSet(boolean value) {
      if (!value) {
        this.exportDir = null;
      }
    }

    public int getWriteMode() {
      return this.writeMode;
    }

    public hdfsToRdbms_args setWriteMode(int writeMode) {
      this.writeMode = writeMode;
      setWriteModeIsSet(true);
      return this;
    }

    public void unsetWriteMode() {
      __isset_bitfield = org.apache.thrift.EncodingUtils.clearBit(__isset_bitfield, __WRITEMODE_ISSET_ID);
    }

    /** Returns true if field writeMode is set (has been assigned a value) and false otherwise */
    public boolean isSetWriteMode() {
      return org.apache.thrift.EncodingUtils.testBit(__isset_bitfield, __WRITEMODE_ISSET_ID);
    }

    public void setWriteModeIsSet(boolean value) {
      __isset_bitfield = org.apache.thrift.EncodingUtils.setBit(__isset_bitfield, __WRITEMODE_ISSET_ID, value);
    }

    public java.lang.String getUpdateKey() {
      return this.updateKey;
    }

    public hdfsToRdbms_args setUpdateKey(java.lang.String updateKey) {
      this.updateKey = updateKey;
      return this;
    }

    public void unsetUpdateKey() {
      this.updateKey = null;
    }

    /** Returns true if field updateKey is set (has been assigned a value) and false otherwise */
    public boolean isSetUpdateKey() {
      return this.updateKey != null;
    }

    public void setUpdateKeyIsSet(boolean value) {
      if (!value) {
        this.updateKey = null;
      }
    }

    public java.lang.String getNumMappers() {
      return this.numMappers;
    }

    public hdfsToRdbms_args setNumMappers(java.lang.String numMappers) {
      this.numMappers = numMappers;
      return this;
    }

    public void unsetNumMappers() {
      this.numMappers = null;
    }

    /** Returns true if field numMappers is set (has been assigned a value) and false otherwise */
    public boolean isSetNumMappers() {
      return this.numMappers != null;
    }

    public void setNumMappersIsSet(boolean value) {
      if (!value) {
        this.numMappers = null;
      }
    }

    public java.lang.String getFileSeparator() {
      return this.fileSeparator;
    }

    public hdfsToRdbms_args setFileSeparator(java.lang.String fileSeparator) {
      this.fileSeparator = fileSeparator;
      return this;
    }

    public void unsetFileSeparator() {
      this.fileSeparator = null;
    }

    /** Returns true if field fileSeparator is set (has been assigned a value) and false otherwise */
    public boolean isSetFileSeparator() {
      return this.fileSeparator != null;
    }

    public void setFileSeparatorIsSet(boolean value) {
      if (!value) {
        this.fileSeparator = null;
      }
    }

    public java.lang.String getExtra() {
      return this.extra;
    }

    public hdfsToRdbms_args setExtra(java.lang.String extra) {
      this.extra = extra;
      return this;
    }

    public void unsetExtra() {
      this.extra = null;
    }

    /** Returns true if field extra is set (has been assigned a value) and false otherwise */
    public boolean isSetExtra() {
      return this.extra != null;
    }

    public void setExtraIsSet(boolean value) {
      if (!value) {
        this.extra = null;
      }
    }

    public DKDBConf getDkdbConf() {
      return this.dkdbConf;
    }

    public hdfsToRdbms_args setDkdbConf(DKDBConf dkdbConf) {
      this.dkdbConf = dkdbConf;
      return this;
    }

    public void unsetDkdbConf() {
      this.dkdbConf = null;
    }

    /** Returns true if field dkdbConf is set (has been assigned a value) and false otherwise */
    public boolean isSetDkdbConf() {
      return this.dkdbConf != null;
    }

    public void setDkdbConfIsSet(boolean value) {
      if (!value) {
        this.dkdbConf = null;
      }
    }

    public void setFieldValue(_Fields field, java.lang.Object value) {
      switch (field) {
      case CONNECT:
        if (value == null) {
          unsetConnect();
        } else {
          setConnect((java.lang.String)value);
        }
        break;

      case USERNAME:
        if (value == null) {
          unsetUsername();
        } else {
          setUsername((java.lang.String)value);
        }
        break;

      case PASSWORD:
        if (value == null) {
          unsetPassword();
        } else {
          setPassword((java.lang.String)value);
        }
        break;

      case TABLE:
        if (value == null) {
          unsetTable();
        } else {
          setTable((java.lang.String)value);
        }
        break;

      case EXPORT_DIR:
        if (value == null) {
          unsetExportDir();
        } else {
          setExportDir((java.lang.String)value);
        }
        break;

      case WRITE_MODE:
        if (value == null) {
          unsetWriteMode();
        } else {
          setWriteMode((java.lang.Integer)value);
        }
        break;

      case UPDATE_KEY:
        if (value == null) {
          unsetUpdateKey();
        } else {
          setUpdateKey((java.lang.String)value);
        }
        break;

      case NUM_MAPPERS:
        if (value == null) {
          unsetNumMappers();
        } else {
          setNumMappers((java.lang.String)value);
        }
        break;

      case FILE_SEPARATOR:
        if (value == null) {
          unsetFileSeparator();
        } else {
          setFileSeparator((java.lang.String)value);
        }
        break;

      case EXTRA:
        if (value == null) {
          unsetExtra();
        } else {
          setExtra((java.lang.String)value);
        }
        break;

      case DKDB_CONF:
        if (value == null) {
          unsetDkdbConf();
        } else {
          setDkdbConf((DKDBConf)value);
        }
        break;

      }
    }

    public java.lang.Object getFieldValue(_Fields field) {
      switch (field) {
      case CONNECT:
        return getConnect();

      case USERNAME:
        return getUsername();

      case PASSWORD:
        return getPassword();

      case TABLE:
        return getTable();

      case EXPORT_DIR:
        return getExportDir();

      case WRITE_MODE:
        return getWriteMode();

      case UPDATE_KEY:
        return getUpdateKey();

      case NUM_MAPPERS:
        return getNumMappers();

      case FILE_SEPARATOR:
        return getFileSeparator();

      case EXTRA:
        return getExtra();

      case DKDB_CONF:
        return getDkdbConf();

      }
      throw new java.lang.IllegalStateException();
    }

    /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      if (field == null) {
        throw new java.lang.IllegalArgumentException();
      }

      switch (field) {
      case CONNECT:
        return isSetConnect();
      case USERNAME:
        return isSetUsername();
      case PASSWORD:
        return isSetPassword();
      case TABLE:
        return isSetTable();
      case EXPORT_DIR:
        return isSetExportDir();
      case WRITE_MODE:
        return isSetWriteMode();
      case UPDATE_KEY:
        return isSetUpdateKey();
      case NUM_MAPPERS:
        return isSetNumMappers();
      case FILE_SEPARATOR:
        return isSetFileSeparator();
      case EXTRA:
        return isSetExtra();
      case DKDB_CONF:
        return isSetDkdbConf();
      }
      throw new java.lang.IllegalStateException();
    }

    @Override
    public boolean equals(java.lang.Object that) {
      if (that == null)
        return false;
      if (that instanceof hdfsToRdbms_args)
        return this.equals((hdfsToRdbms_args)that);
      return false;
    }

    public boolean equals(hdfsToRdbms_args that) {
      if (that == null)
        return false;
      if (this == that)
        return true;

      boolean this_present_connect = true && this.isSetConnect();
      boolean that_present_connect = true && that.isSetConnect();
      if (this_present_connect || that_present_connect) {
        if (!(this_present_connect && that_present_connect))
          return false;
        if (!this.connect.equals(that.connect))
          return false;
      }

      boolean this_present_username = true && this.isSetUsername();
      boolean that_present_username = true && that.isSetUsername();
      if (this_present_username || that_present_username) {
        if (!(this_present_username && that_present_username))
          return false;
        if (!this.username.equals(that.username))
          return false;
      }

      boolean this_present_password = true && this.isSetPassword();
      boolean that_present_password = true && that.isSetPassword();
      if (this_present_password || that_present_password) {
        if (!(this_present_password && that_present_password))
          return false;
        if (!this.password.equals(that.password))
          return false;
      }

      boolean this_present_table = true && this.isSetTable();
      boolean that_present_table = true && that.isSetTable();
      if (this_present_table || that_present_table) {
        if (!(this_present_table && that_present_table))
          return false;
        if (!this.table.equals(that.table))
          return false;
      }

      boolean this_present_exportDir = true && this.isSetExportDir();
      boolean that_present_exportDir = true && that.isSetExportDir();
      if (this_present_exportDir || that_present_exportDir) {
        if (!(this_present_exportDir && that_present_exportDir))
          return false;
        if (!this.exportDir.equals(that.exportDir))
          return false;
      }

      boolean this_present_writeMode = true;
      boolean that_present_writeMode = true;
      if (this_present_writeMode || that_present_writeMode) {
        if (!(this_present_writeMode && that_present_writeMode))
          return false;
        if (this.writeMode != that.writeMode)
          return false;
      }

      boolean this_present_updateKey = true && this.isSetUpdateKey();
      boolean that_present_updateKey = true && that.isSetUpdateKey();
      if (this_present_updateKey || that_present_updateKey) {
        if (!(this_present_updateKey && that_present_updateKey))
          return false;
        if (!this.updateKey.equals(that.updateKey))
          return false;
      }

      boolean this_present_numMappers = true && this.isSetNumMappers();
      boolean that_present_numMappers = true && that.isSetNumMappers();
      if (this_present_numMappers || that_present_numMappers) {
        if (!(this_present_numMappers && that_present_numMappers))
          return false;
        if (!this.numMappers.equals(that.numMappers))
          return false;
      }

      boolean this_present_fileSeparator = true && this.isSetFileSeparator();
      boolean that_present_fileSeparator = true && that.isSetFileSeparator();
      if (this_present_fileSeparator || that_present_fileSeparator) {
        if (!(this_present_fileSeparator && that_present_fileSeparator))
          return false;
        if (!this.fileSeparator.equals(that.fileSeparator))
          return false;
      }

      boolean this_present_extra = true && this.isSetExtra();
      boolean that_present_extra = true && that.isSetExtra();
      if (this_present_extra || that_present_extra) {
        if (!(this_present_extra && that_present_extra))
          return false;
        if (!this.extra.equals(that.extra))
          return false;
      }

      boolean this_present_dkdbConf = true && this.isSetDkdbConf();
      boolean that_present_dkdbConf = true && that.isSetDkdbConf();
      if (this_present_dkdbConf || that_present_dkdbConf) {
        if (!(this_present_dkdbConf && that_present_dkdbConf))
          return false;
        if (!this.dkdbConf.equals(that.dkdbConf))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      int hashCode = 1;

      hashCode = hashCode * 8191 + ((isSetConnect()) ? 131071 : 524287);
      if (isSetConnect())
        hashCode = hashCode * 8191 + connect.hashCode();

      hashCode = hashCode * 8191 + ((isSetUsername()) ? 131071 : 524287);
      if (isSetUsername())
        hashCode = hashCode * 8191 + username.hashCode();

      hashCode = hashCode * 8191 + ((isSetPassword()) ? 131071 : 524287);
      if (isSetPassword())
        hashCode = hashCode * 8191 + password.hashCode();

      hashCode = hashCode * 8191 + ((isSetTable()) ? 131071 : 524287);
      if (isSetTable())
        hashCode = hashCode * 8191 + table.hashCode();

      hashCode = hashCode * 8191 + ((isSetExportDir()) ? 131071 : 524287);
      if (isSetExportDir())
        hashCode = hashCode * 8191 + exportDir.hashCode();

      hashCode = hashCode * 8191 + writeMode;

      hashCode = hashCode * 8191 + ((isSetUpdateKey()) ? 131071 : 524287);
      if (isSetUpdateKey())
        hashCode = hashCode * 8191 + updateKey.hashCode();

      hashCode = hashCode * 8191 + ((isSetNumMappers()) ? 131071 : 524287);
      if (isSetNumMappers())
        hashCode = hashCode * 8191 + numMappers.hashCode();

      hashCode = hashCode * 8191 + ((isSetFileSeparator()) ? 131071 : 524287);
      if (isSetFileSeparator())
        hashCode = hashCode * 8191 + fileSeparator.hashCode();

      hashCode = hashCode * 8191 + ((isSetExtra()) ? 131071 : 524287);
      if (isSetExtra())
        hashCode = hashCode * 8191 + extra.hashCode();

      hashCode = hashCode * 8191 + ((isSetDkdbConf()) ? 131071 : 524287);
      if (isSetDkdbConf())
        hashCode = hashCode * 8191 + dkdbConf.hashCode();

      return hashCode;
    }

    @Override
    public int compareTo(hdfsToRdbms_args other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;

      lastComparison = java.lang.Boolean.valueOf(isSetConnect()).compareTo(other.isSetConnect());
      if (lastComparison != 0) {
        return lastComparison;
      }
      if (isSetConnect()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.connect, other.connect);
        if (lastComparison != 0) {
          return lastComparison;
        }
      }
      lastComparison = java.lang.Boolean.valueOf(isSetUsername()).compareTo(other.isSetUsername());
      if (lastComparison != 0) {
        return lastComparison;
      }
      if (isSetUsername()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.username, other.username);
        if (lastComparison != 0) {
          return lastComparison;
        }
      }
      lastComparison = java.lang.Boolean.valueOf(isSetPassword()).compareTo(other.isSetPassword());
      if (lastComparison != 0) {
        return lastComparison;
      }
      if (isSetPassword()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.password, other.password);
        if (lastComparison != 0) {
          return lastComparison;
        }
      }
      lastComparison = java.lang.Boolean.valueOf(isSetTable()).compareTo(other.isSetTable());
      if (lastComparison != 0) {
        return lastComparison;
      }
      if (isSetTable()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.table, other.table);
        if (lastComparison != 0) {
          return lastComparison;
        }
      }
      lastComparison = java.lang.Boolean.valueOf(isSetExportDir()).compareTo(other.isSetExportDir());
      if (lastComparison != 0) {
        return lastComparison;
      }
      if (isSetExportDir()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.exportDir, other.exportDir);
        if (lastComparison != 0) {
          return lastComparison;
        }
      }
      lastComparison = java.lang.Boolean.valueOf(isSetWriteMode()).compareTo(other.isSetWriteMode());
      if (lastComparison != 0) {
        return lastComparison;
      }
      if (isSetWriteMode()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.writeMode, other.writeMode);
        if (lastComparison != 0) {
          return lastComparison;
        }
      }
      lastComparison = java.lang.Boolean.valueOf(isSetUpdateKey()).compareTo(other.isSetUpdateKey());
      if (lastComparison != 0) {
        return lastComparison;
      }
      if (isSetUpdateKey()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.updateKey, other.updateKey);
        if (lastComparison != 0) {
          return lastComparison;
        }
      }
      lastComparison = java.lang.Boolean.valueOf(isSetNumMappers()).compareTo(other.isSetNumMappers());
      if (lastComparison != 0) {
        return lastComparison;
      }
      if (isSetNumMappers()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.numMappers, other.numMappers);
        if (lastComparison != 0) {
          return lastComparison;
        }
      }
      lastComparison = java.lang.Boolean.valueOf(isSetFileSeparator()).compareTo(other.isSetFileSeparator());
      if (lastComparison != 0) {
        return lastComparison;
      }
      if (isSetFileSeparator()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.fileSeparator, other.fileSeparator);
        if (lastComparison != 0) {
          return lastComparison;
        }
      }
      lastComparison = java.lang.Boolean.valueOf(isSetExtra()).compareTo(other.isSetExtra());
      if (lastComparison != 0) {
        return lastComparison;
      }
      if (isSetExtra()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.extra, other.extra);
        if (lastComparison != 0) {
          return lastComparison;
        }
      }
      lastComparison = java.lang.Boolean.valueOf(isSetDkdbConf()).compareTo(other.isSetDkdbConf());
      if (lastComparison != 0) {
        return lastComparison;
      }
      if (isSetDkdbConf()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.dkdbConf, other.dkdbConf);
        if (lastComparison != 0) {
          return lastComparison;
        }
      }
      return 0;
    }

    public _Fields fieldForId(int fieldId) {
      return _Fields.findByThriftId(fieldId);
    }

    public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException {
      scheme(iprot).read(iprot, this);
    }

    public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException {
      scheme(oprot).write(oprot, this);
    }

    @Override
    public java.lang.String toString() {
      java.lang.StringBuilder sb = new java.lang.StringBuilder("hdfsToRdbms_args(");
      boolean first = true;

      sb.append("connect:");
      if (this.connect == null) {
        sb.append("null");
      } else {
        sb.append(this.connect);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("username:");
      if (this.username == null) {
        sb.append("null");
      } else {
        sb.append(this.username);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("password:");
      if (this.password == null) {
        sb.append("null");
      } else {
        sb.append(this.password);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("table:");
      if (this.table == null) {
        sb.append("null");
      } else {
        sb.append(this.table);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("exportDir:");
      if (this.exportDir == null) {
        sb.append("null");
      } else {
        sb.append(this.exportDir);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("writeMode:");
      sb.append(this.writeMode);
      first = false;
      if (!first) sb.append(", ");
      sb.append("updateKey:");
      if (this.updateKey == null) {
        sb.append("null");
      } else {
        sb.append(this.updateKey);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("numMappers:");
      if (this.numMappers == null) {
        sb.append("null");
      } else {
        sb.append(this.numMappers);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("fileSeparator:");
      if (this.fileSeparator == null) {
        sb.append("null");
      } else {
        sb.append(this.fileSeparator);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("extra:");
      if (this.extra == null) {
        sb.append("null");
      } else {
        sb.append(this.extra);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("dkdbConf:");
      if (this.dkdbConf == null) {
        sb.append("null");
      } else {
        sb.append(this.dkdbConf);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws org.apache.thrift.TException {
      // check for required fields
      // check for sub-struct validity
      if (dkdbConf != null) {
        dkdbConf.validate();
      }
    }

    private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
      try {
        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));
      } catch (org.apache.thrift.TException te) {
        throw new java.io.IOException(te);
      }
    }

    private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, java.lang.ClassNotFoundException {
      try {
        // it doesn't seem like you should have to do this, but java serialization is wacky, and doesn't call the default constructor.
        __isset_bitfield = 0;
        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));
      } catch (org.apache.thrift.TException te) {
        throw new java.io.IOException(te);
      }
    }

    private static class hdfsToRdbms_argsStandardSchemeFactory implements org.apache.thrift.scheme.SchemeFactory {
      public hdfsToRdbms_argsStandardScheme getScheme() {
        return new hdfsToRdbms_argsStandardScheme();
      }
    }

    private static class hdfsToRdbms_argsStandardScheme extends org.apache.thrift.scheme.StandardScheme<hdfsToRdbms_args> {

      public void read(org.apache.thrift.protocol.TProtocol iprot, hdfsToRdbms_args struct) throws org.apache.thrift.TException {
        org.apache.thrift.protocol.TField schemeField;
        iprot.readStructBegin();
        while (true)
        {
          schemeField = iprot.readFieldBegin();
          if (schemeField.type == org.apache.thrift.protocol.TType.STOP) { 
            break;
          }
          switch (schemeField.id) {
            case 1: // CONNECT
              if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
                struct.connect = iprot.readString();
                struct.setConnectIsSet(true);
              } else { 
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
              }
              break;
            case 2: // USERNAME
              if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
                struct.username = iprot.readString();
                struct.setUsernameIsSet(true);
              } else { 
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
              }
              break;
            case 3: // PASSWORD
              if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
                struct.password = iprot.readString();
                struct.setPasswordIsSet(true);
              } else { 
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
              }
              break;
            case 4: // TABLE
              if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
                struct.table = iprot.readString();
                struct.setTableIsSet(true);
              } else { 
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
              }
              break;
            case 5: // EXPORT_DIR
              if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
                struct.exportDir = iprot.readString();
                struct.setExportDirIsSet(true);
              } else { 
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
              }
              break;
            case 6: // WRITE_MODE
              if (schemeField.type == org.apache.thrift.protocol.TType.I32) {
                struct.writeMode = iprot.readI32();
                struct.setWriteModeIsSet(true);
              } else { 
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
              }
              break;
            case 7: // UPDATE_KEY
              if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
                struct.updateKey = iprot.readString();
                struct.setUpdateKeyIsSet(true);
              } else { 
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
              }
              break;
            case 8: // NUM_MAPPERS
              if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
                struct.numMappers = iprot.readString();
                struct.setNumMappersIsSet(true);
              } else { 
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
              }
              break;
            case 9: // FILE_SEPARATOR
              if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
                struct.fileSeparator = iprot.readString();
                struct.setFileSeparatorIsSet(true);
              } else { 
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
              }
              break;
            case 10: // EXTRA
              if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
                struct.extra = iprot.readString();
                struct.setExtraIsSet(true);
              } else { 
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
              }
              break;
            case 11: // DKDB_CONF
              if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
                struct.dkdbConf = new DKDBConf();
                struct.dkdbConf.read(iprot);
                struct.setDkdbConfIsSet(true);
              } else { 
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
              }
              break;
            default:
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
          }
          iprot.readFieldEnd();
        }
        iprot.readStructEnd();

        // check for required fields of primitive type, which can't be checked in the validate method
        struct.validate();
      }

      public void write(org.apache.thrift.protocol.TProtocol oprot, hdfsToRdbms_args struct) throws org.apache.thrift.TException {
        struct.validate();

        oprot.writeStructBegin(STRUCT_DESC);
        if (struct.connect != null) {
          oprot.writeFieldBegin(CONNECT_FIELD_DESC);
          oprot.writeString(struct.connect);
          oprot.writeFieldEnd();
        }
        if (struct.username != null) {
          oprot.writeFieldBegin(USERNAME_FIELD_DESC);
          oprot.writeString(struct.username);
          oprot.writeFieldEnd();
        }
        if (struct.password != null) {
          oprot.writeFieldBegin(PASSWORD_FIELD_DESC);
          oprot.writeString(struct.password);
          oprot.writeFieldEnd();
        }
        if (struct.table != null) {
          oprot.writeFieldBegin(TABLE_FIELD_DESC);
          oprot.writeString(struct.table);
          oprot.writeFieldEnd();
        }
        if (struct.exportDir != null) {
          oprot.writeFieldBegin(EXPORT_DIR_FIELD_DESC);
          oprot.writeString(struct.exportDir);
          oprot.writeFieldEnd();
        }
        oprot.writeFieldBegin(WRITE_MODE_FIELD_DESC);
        oprot.writeI32(struct.writeMode);
        oprot.writeFieldEnd();
        if (struct.updateKey != null) {
          oprot.writeFieldBegin(UPDATE_KEY_FIELD_DESC);
          oprot.writeString(struct.updateKey);
          oprot.writeFieldEnd();
        }
        if (struct.numMappers != null) {
          oprot.writeFieldBegin(NUM_MAPPERS_FIELD_DESC);
          oprot.writeString(struct.numMappers);
          oprot.writeFieldEnd();
        }
        if (struct.fileSeparator != null) {
          oprot.writeFieldBegin(FILE_SEPARATOR_FIELD_DESC);
          oprot.writeString(struct.fileSeparator);
          oprot.writeFieldEnd();
        }
        if (struct.extra != null) {
          oprot.writeFieldBegin(EXTRA_FIELD_DESC);
          oprot.writeString(struct.extra);
          oprot.writeFieldEnd();
        }
        if (struct.dkdbConf != null) {
          oprot.writeFieldBegin(DKDB_CONF_FIELD_DESC);
          struct.dkdbConf.write(oprot);
          oprot.writeFieldEnd();
        }
        oprot.writeFieldStop();
        oprot.writeStructEnd();
      }

    }

    private static class hdfsToRdbms_argsTupleSchemeFactory implements org.apache.thrift.scheme.SchemeFactory {
      public hdfsToRdbms_argsTupleScheme getScheme() {
        return new hdfsToRdbms_argsTupleScheme();
      }
    }

    private static class hdfsToRdbms_argsTupleScheme extends org.apache.thrift.scheme.TupleScheme<hdfsToRdbms_args> {

      @Override
      public void write(org.apache.thrift.protocol.TProtocol prot, hdfsToRdbms_args struct) throws org.apache.thrift.TException {
        org.apache.thrift.protocol.TTupleProtocol oprot = (org.apache.thrift.protocol.TTupleProtocol) prot;
        java.util.BitSet optionals = new java.util.BitSet();
        if (struct.isSetConnect()) {
          optionals.set(0);
        }
        if (struct.isSetUsername()) {
          optionals.set(1);
        }
        if (struct.isSetPassword()) {
          optionals.set(2);
        }
        if (struct.isSetTable()) {
          optionals.set(3);
        }
        if (struct.isSetExportDir()) {
          optionals.set(4);
        }
        if (struct.isSetWriteMode()) {
          optionals.set(5);
        }
        if (struct.isSetUpdateKey()) {
          optionals.set(6);
        }
        if (struct.isSetNumMappers()) {
          optionals.set(7);
        }
        if (struct.isSetFileSeparator()) {
          optionals.set(8);
        }
        if (struct.isSetExtra()) {
          optionals.set(9);
        }
        if (struct.isSetDkdbConf()) {
          optionals.set(10);
        }
        oprot.writeBitSet(optionals, 11);
        if (struct.isSetConnect()) {
          oprot.writeString(struct.connect);
        }
        if (struct.isSetUsername()) {
          oprot.writeString(struct.username);
        }
        if (struct.isSetPassword()) {
          oprot.writeString(struct.password);
        }
        if (struct.isSetTable()) {
          oprot.writeString(struct.table);
        }
        if (struct.isSetExportDir()) {
          oprot.writeString(struct.exportDir);
        }
        if (struct.isSetWriteMode()) {
          oprot.writeI32(struct.writeMode);
        }
        if (struct.isSetUpdateKey()) {
          oprot.writeString(struct.updateKey);
        }
        if (struct.isSetNumMappers()) {
          oprot.writeString(struct.numMappers);
        }
        if (struct.isSetFileSeparator()) {
          oprot.writeString(struct.fileSeparator);
        }
        if (struct.isSetExtra()) {
          oprot.writeString(struct.extra);
        }
        if (struct.isSetDkdbConf()) {
          struct.dkdbConf.write(oprot);
        }
      }

      @Override
      public void read(org.apache.thrift.protocol.TProtocol prot, hdfsToRdbms_args struct) throws org.apache.thrift.TException {
        org.apache.thrift.protocol.TTupleProtocol iprot = (org.apache.thrift.protocol.TTupleProtocol) prot;
        java.util.BitSet incoming = iprot.readBitSet(11);
        if (incoming.get(0)) {
          struct.connect = iprot.readString();
          struct.setConnectIsSet(true);
        }
        if (incoming.get(1)) {
          struct.username = iprot.readString();
          struct.setUsernameIsSet(true);
        }
        if (incoming.get(2)) {
          struct.password = iprot.readString();
          struct.setPasswordIsSet(true);
        }
        if (incoming.get(3)) {
          struct.table = iprot.readString();
          struct.setTableIsSet(true);
        }
        if (incoming.get(4)) {
          struct.exportDir = iprot.readString();
          struct.setExportDirIsSet(true);
        }
        if (incoming.get(5)) {
          struct.writeMode = iprot.readI32();
          struct.setWriteModeIsSet(true);
        }
        if (incoming.get(6)) {
          struct.updateKey = iprot.readString();
          struct.setUpdateKeyIsSet(true);
        }
        if (incoming.get(7)) {
          struct.numMappers = iprot.readString();
          struct.setNumMappersIsSet(true);
        }
        if (incoming.get(8)) {
          struct.fileSeparator = iprot.readString();
          struct.setFileSeparatorIsSet(true);
        }
        if (incoming.get(9)) {
          struct.extra = iprot.readString();
          struct.setExtraIsSet(true);
        }
        if (incoming.get(10)) {
          struct.dkdbConf = new DKDBConf();
          struct.dkdbConf.read(iprot);
          struct.setDkdbConfIsSet(true);
        }
      }
    }

    private static <S extends org.apache.thrift.scheme.IScheme> S scheme(org.apache.thrift.protocol.TProtocol proto) {
      return (org.apache.thrift.scheme.StandardScheme.class.equals(proto.getScheme()) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY).getScheme();
    }
  }

  public static class hdfsToRdbms_result implements org.apache.thrift.TBase<hdfsToRdbms_result, hdfsToRdbms_result._Fields>, java.io.Serializable, Cloneable, Comparable<hdfsToRdbms_result>   {
    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("hdfsToRdbms_result");

    private static final org.apache.thrift.protocol.TField SUCCESS_FIELD_DESC = new org.apache.thrift.protocol.TField("success", org.apache.thrift.protocol.TType.STRUCT, (short)0);

    private static final org.apache.thrift.scheme.SchemeFactory STANDARD_SCHEME_FACTORY = new hdfsToRdbms_resultStandardSchemeFactory();
    private static final org.apache.thrift.scheme.SchemeFactory TUPLE_SCHEME_FACTORY = new hdfsToRdbms_resultTupleSchemeFactory();

    public ResultEntity success; // required

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements org.apache.thrift.TFieldIdEnum {
      SUCCESS((short)0, "success");

      private static final java.util.Map<java.lang.String, _Fields> byName = new java.util.HashMap<java.lang.String, _Fields>();

      static {
        for (_Fields field : java.util.EnumSet.allOf(_Fields.class)) {
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        switch(fieldId) {
          case 0: // SUCCESS
            return SUCCESS;
          default:
            return null;
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new java.lang.IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(java.lang.String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final java.lang.String _fieldName;

      _Fields(short thriftId, java.lang.String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public java.lang.String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments
    public static final java.util.Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
    static {
      java.util.Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new java.util.EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
      tmpMap.put(_Fields.SUCCESS, new org.apache.thrift.meta_data.FieldMetaData("success", org.apache.thrift.TFieldRequirementType.DEFAULT, 
          new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, ResultEntity.class)));
      metaDataMap = java.util.Collections.unmodifiableMap(tmpMap);
      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(hdfsToRdbms_result.class, metaDataMap);
    }

    public hdfsToRdbms_result() {
    }

    public hdfsToRdbms_result(
      ResultEntity success)
    {
      this();
      this.success = success;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public hdfsToRdbms_result(hdfsToRdbms_result other) {
      if (other.isSetSuccess()) {
        this.success = new ResultEntity(other.success);
      }
    }

    public hdfsToRdbms_result deepCopy() {
      return new hdfsToRdbms_result(this);
    }

    @Override
    public void clear() {
      this.success = null;
    }

    public ResultEntity getSuccess() {
      return this.success;
    }

    public hdfsToRdbms_result setSuccess(ResultEntity success) {
      this.success = success;
      return this;
    }

    public void unsetSuccess() {
      this.success = null;
    }

    /** Returns true if field success is set (has been assigned a value) and false otherwise */
    public boolean isSetSuccess() {
      return this.success != null;
    }

    public void setSuccessIsSet(boolean value) {
      if (!value) {
        this.success = null;
      }
    }

    public void setFieldValue(_Fields field, java.lang.Object value) {
      switch (field) {
      case SUCCESS:
        if (value == null) {
          unsetSuccess();
        } else {
          setSuccess((ResultEntity)value);
        }
        break;

      }
    }

    public java.lang.Object getFieldValue(_Fields field) {
      switch (field) {
      case SUCCESS:
        return getSuccess();

      }
      throw new java.lang.IllegalStateException();
    }

    /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      if (field == null) {
        throw new java.lang.IllegalArgumentException();
      }

      switch (field) {
      case SUCCESS:
        return isSetSuccess();
      }
      throw new java.lang.IllegalStateException();
    }

    @Override
    public boolean equals(java.lang.Object that) {
      if (that == null)
        return false;
      if (that instanceof hdfsToRdbms_result)
        return this.equals((hdfsToRdbms_result)that);
      return false;
    }

    public boolean equals(hdfsToRdbms_result that) {
      if (that == null)
        return false;
      if (this == that)
        return true;

      boolean this_present_success = true && this.isSetSuccess();
      boolean that_present_success = true && that.isSetSuccess();
      if (this_present_success || that_present_success) {
        if (!(this_present_success && that_present_success))
          return false;
        if (!this.success.equals(that.success))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      int hashCode = 1;

      hashCode = hashCode * 8191 + ((isSetSuccess()) ? 131071 : 524287);
      if (isSetSuccess())
        hashCode = hashCode * 8191 + success.hashCode();

      return hashCode;
    }

    @Override
    public int compareTo(hdfsToRdbms_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;

      lastComparison = java.lang.Boolean.valueOf(isSetSuccess()).compareTo(other.isSetSuccess());
      if (lastComparison != 0) {
        return lastComparison;
      }
      if (isSetSuccess()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.success, other.success);
        if (lastComparison != 0) {
          return lastComparison;
        }
      }
      return 0;
    }

    public _Fields fieldForId(int fieldId) {
      return _Fields.findByThriftId(fieldId);
    }

    public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException {
      scheme(iprot).read(iprot, this);
    }

    public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException {
      scheme(oprot).write(oprot, this);
      }

    @Override
    public java.lang.String toString() {
      java.lang.StringBuilder sb = new java.lang.StringBuilder("hdfsToRdbms_result(");
      boolean first = true;

      sb.append("success:");
      if (this.success == null) {
        sb.append("null");
      } else {
        sb.append(this.success);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws org.apache.thrift.TException {
      // check for required fields
      // check for sub-struct validity
      if (success != null) {
        success.validate();
      }
    }

    private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
      try {
        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));
      } catch (org.apache.thrift.TException te) {
        throw new java.io.IOException(te);
      }
    }

    private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, java.lang.ClassNotFoundException {
      try {
        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));
      } catch (org.apache.thrift.TException te) {
        throw new java.io.IOException(te);
      }
    }

    private static class hdfsToRdbms_resultStandardSchemeFactory implements org.apache.thrift.scheme.SchemeFactory {
      public hdfsToRdbms_resultStandardScheme getScheme() {
        return new hdfsToRdbms_resultStandardScheme();
      }
    }

    private static class hdfsToRdbms_resultStandardScheme extends org.apache.thrift.scheme.StandardScheme<hdfsToRdbms_result> {

      public void read(org.apache.thrift.protocol.TProtocol iprot, hdfsToRdbms_result struct) throws org.apache.thrift.TException {
        org.apache.thrift.protocol.TField schemeField;
        iprot.readStructBegin();
        while (true)
        {
          schemeField = iprot.readFieldBegin();
          if (schemeField.type == org.apache.thrift.protocol.TType.STOP) { 
            break;
          }
          switch (schemeField.id) {
            case 0: // SUCCESS
              if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
                struct.success = new ResultEntity();
                struct.success.read(iprot);
                struct.setSuccessIsSet(true);
              } else { 
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
              }
              break;
            default:
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
          }
          iprot.readFieldEnd();
        }
        iprot.readStructEnd();

        // check for required fields of primitive type, which can't be checked in the validate method
        struct.validate();
      }

      public void write(org.apache.thrift.protocol.TProtocol oprot, hdfsToRdbms_result struct) throws org.apache.thrift.TException {
        struct.validate();

        oprot.writeStructBegin(STRUCT_DESC);
        if (struct.success != null) {
          oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
          struct.success.write(oprot);
          oprot.writeFieldEnd();
        }
        oprot.writeFieldStop();
        oprot.writeStructEnd();
      }

    }

    private static class hdfsToRdbms_resultTupleSchemeFactory implements org.apache.thrift.scheme.SchemeFactory {
      public hdfsToRdbms_resultTupleScheme getScheme() {
        return new hdfsToRdbms_resultTupleScheme();
      }
    }

    private static class hdfsToRdbms_resultTupleScheme extends org.apache.thrift.scheme.TupleScheme<hdfsToRdbms_result> {

      @Override
      public void write(org.apache.thrift.protocol.TProtocol prot, hdfsToRdbms_result struct) throws org.apache.thrift.TException {
        org.apache.thrift.protocol.TTupleProtocol oprot = (org.apache.thrift.protocol.TTupleProtocol) prot;
        java.util.BitSet optionals = new java.util.BitSet();
        if (struct.isSetSuccess()) {
          optionals.set(0);
        }
        oprot.writeBitSet(optionals, 1);
        if (struct.isSetSuccess()) {
          struct.success.write(oprot);
        }
      }

      @Override
      public void read(org.apache.thrift.protocol.TProtocol prot, hdfsToRdbms_result struct) throws org.apache.thrift.TException {
        org.apache.thrift.protocol.TTupleProtocol iprot = (org.apache.thrift.protocol.TTupleProtocol) prot;
        java.util.BitSet incoming = iprot.readBitSet(1);
        if (incoming.get(0)) {
          struct.success = new ResultEntity();
          struct.success.read(iprot);
          struct.setSuccessIsSet(true);
        }
      }
    }

    private static <S extends org.apache.thrift.scheme.IScheme> S scheme(org.apache.thrift.protocol.TProtocol proto) {
      return (org.apache.thrift.scheme.StandardScheme.class.equals(proto.getScheme()) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY).getScheme();
    }
  }

}
