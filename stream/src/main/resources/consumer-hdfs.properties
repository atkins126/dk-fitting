# zookeeper的列表及端口，最好指定3个以上. eg : localhost:2181,localhost2:2181,localhost3:2181。
consumer.hdfs.zookeeper.connect=192.168.1.166:2181
#指定当前consumer的组名称。同一组内数据只能消费同一条数据一次，不同组内可以各消费一次。
consumer.hdfs.group.id=1
#指定kafka的消费的topic的名称列表，多个用逗号隔开。
consumer.hdfs.kafka.topicNames=my-topic
#指定kafka每个topic的消费者线程数，与kafka的分区相对应，小于等于kafka的分区数。
consumer.hdfs.kafka.topicConsumerNum=3
#指定连接hdfs的url地址，如果集群为ha，请指定两个namenode的地址。
consumer.hdfs.hdfsUrl=192.168.1.166:9000
#指定该topic要存储到hdfs的路径及文件夹名称。
consumer.hdfs.hdfsFilePath=/test/data


#security.protocol=SSL
#ssl.truststore.location=key/kafka.client.truststore.jks
#ssl.truststore.password=gydsj5
#ssl.keystore.location=key/kafka.server.keystore.jks
#ssl.keystore.password=gydsj5
#ssl.key.password=gydsj5
#指定key的序列化类
consumer.hdfs.security.protocol=
#指定kafka.client.truststore.jks文件路径
consumer.hdfs.ssl.truststore.location=
#指定truststore的密码
consumer.hdfs.ssl.truststore.password=
#指定kafka.server.keystore.jks文件路径
consumer.hdfs.ssl.keystore.location=
#指定keystore的密码
consumer.hdfs.ssl.keystore.password=
#指定key密码
consumer.hdfs.ssl.key.password=


#指定zookeeper会话超时时间。
consumer.hdfs.zookeeper.session.timeout.ms=3600000
#kafka是否自动commit 。 请保持默认。
consumer.hdfs.enable.auto.commit=true
# kafka的commit的间隔时间
consumer.hdfs.auto.commit.interval.ms=1000
#指定kafka的会话超时时间
consumer.hdfs.session.timeout.ms=30000
#指定kafka重新启动时消费offset的位置  smallest and largest
consumer.hdfs.auto.offset.reset=smallest
#指定kafka的offset的保存位置
consumer.hdfs.offsets.storage=kafka
#指定kafka的offset是否保存到zookeeper
consumer.hdfs.dual.commit=true

#指定HDFS连接配置项。根据实际情况修改
#consumer.hdfs.hdfs.path=/opt/hadoop-2.6.0/etc/hadoop/core-site.xml
#consumer.hdfs.core.path=/opt/hadoop-2.6.0/etc/hadoop/core-site.xml
#consumer.hdfs.krb5.path=/etc/krb5.conf
#consumer.hdfs.principal.path="hdfs/cdh166@HADOOP.COM"
#consumer.hdfs.keytab.pat="/root/hdfs.keytab"
consumer.hdfs.hdfs.path=
consumer.hdfs.core.path=
consumer.hdfs.krb5.path=
consumer.hdfs.principal.path=
consumer.hdfs.keytab.pat=
